read
Begin
step: 0 epoch: 0 loss: 8732.244140625 loss_input: 74.26129150390625
step: 1000 epoch: 0 loss: 104.65911314466021 loss_input: 82.90865177303165
step: 2000 epoch: 0 loss: 70.17248471959242 loss_input: 81.82647668475333
step: 3000 epoch: 0 loss: 57.96353633083609 loss_input: 81.78666065169033
step: 4000 epoch: 0 loss: 51.52162770621927 loss_input: 81.72312746093262
step: 5000 epoch: 0 loss: 47.40657450747094 loss_input: 81.7118155958652
step: 6000 epoch: 0 loss: 44.62509016060189 loss_input: 81.82137953204088
step: 7000 epoch: 0 loss: 42.546330376363386 loss_input: 82.02888663784638
step: 8000 epoch: 0 loss: 41.10319180638175 loss_input: 81.97418814011773
step: 9000 epoch: 0 loss: 39.86446428420795 loss_input: 82.01544371182065
step: 10000 epoch: 0 loss: 38.773049956261545 loss_input: 81.93579984652902
step: 11000 epoch: 0 loss: 37.89053740240034 loss_input: 82.04943393817892
step: 12000 epoch: 0 loss: 37.0887445062908 loss_input: 82.03426129996166
step: 13000 epoch: 0 loss: 36.36900971007525 loss_input: 81.9440671030113
step: 14000 epoch: 0 loss: 35.80048548791266 loss_input: 82.0846173428321
step: 15000 epoch: 0 loss: 35.29398118132838 loss_input: 82.17203032004898
Save loss: 34.827977101624015 Name: 0_train_model.pth
step: 0 epoch: 1 loss: 33.60812759399414 loss_input: 107.8380126953125
step: 1000 epoch: 1 loss: 26.599059328332647 loss_input: 81.29384860744725
step: 2000 epoch: 1 loss: 26.678376101303673 loss_input: 81.89972454568614
step: 3000 epoch: 1 loss: 26.615261800366216 loss_input: 82.09094518949412
step: 4000 epoch: 1 loss: 26.403553869389974 loss_input: 81.82864568281758
step: 5000 epoch: 1 loss: 26.361620581214414 loss_input: 81.85039249474323
step: 6000 epoch: 1 loss: 26.306406675944864 loss_input: 81.95261966226657
step: 7000 epoch: 1 loss: 26.281372540066233 loss_input: 82.06759466142114
step: 8000 epoch: 1 loss: 26.180829121759274 loss_input: 81.99979034755665
step: 9000 epoch: 1 loss: 26.13262966952977 loss_input: 82.16597769247427
step: 10000 epoch: 1 loss: 26.070401465531624 loss_input: 82.30982495012218
step: 11000 epoch: 1 loss: 26.02689784497047 loss_input: 82.44024300347695
step: 12000 epoch: 1 loss: 25.957435546085424 loss_input: 82.3910833256571
step: 13000 epoch: 1 loss: 25.889718761426487 loss_input: 82.38509376701342
step: 14000 epoch: 1 loss: 25.85923579396303 loss_input: 82.37808229936701
step: 15000 epoch: 1 loss: 25.782575944242268 loss_input: 82.34083384512647
Save loss: 25.684462902337312 Name: 1_train_model.pth
step: 0 epoch: 2 loss: 35.48899459838867 loss_input: 76.7945556640625
step: 1000 epoch: 2 loss: 25.09691257838841 loss_input: 81.41752205314216
step: 2000 epoch: 2 loss: 24.912225667027936 loss_input: 82.71549942802037
step: 3000 epoch: 2 loss: 24.944031825505746 loss_input: 82.61646004066353
step: 4000 epoch: 2 loss: 24.89095854800929 loss_input: 82.5587043180611
step: 5000 epoch: 2 loss: 24.88106028896836 loss_input: 82.5546534125792
step: 6000 epoch: 2 loss: 24.78781378680399 loss_input: 82.52010535272116
step: 7000 epoch: 2 loss: 24.711409652016876 loss_input: 82.58476184310445
step: 8000 epoch: 2 loss: 24.597934526706425 loss_input: 82.62918570267828
step: 9000 epoch: 2 loss: 24.53035734664227 loss_input: 82.49657691842833
step: 10000 epoch: 2 loss: 24.485308817369607 loss_input: 82.46621493856473
step: 11000 epoch: 2 loss: 24.430329627356155 loss_input: 82.47642550517425
step: 12000 epoch: 2 loss: 24.349307145389773 loss_input: 82.43332232384769
step: 13000 epoch: 2 loss: 24.312466171849426 loss_input: 82.3794174082838
step: 14000 epoch: 2 loss: 24.23604671046288 loss_input: 82.37142969838092
step: 15000 epoch: 2 loss: 24.183075228322945 loss_input: 82.38383635345534
Save loss: 24.115492206662893 Name: 2_train_model.pth
step: 0 epoch: 3 loss: 19.502803802490234 loss_input: 80.98583984375
step: 1000 epoch: 3 loss: 23.708493528547105 loss_input: 81.39774373575644
step: 2000 epoch: 3 loss: 23.713821282927718 loss_input: 82.53589080703789
step: 3000 epoch: 3 loss: 23.69547396951896 loss_input: 82.84761189222733
step: 4000 epoch: 3 loss: 23.605001465435834 loss_input: 83.03476920076622
step: 5000 epoch: 3 loss: 23.582371515122635 loss_input: 83.12381747283357
step: 6000 epoch: 3 loss: 23.51740965742287 loss_input: 82.96153547366129
step: 7000 epoch: 3 loss: 23.471941986827744 loss_input: 82.75699002053837
step: 8000 epoch: 3 loss: 23.426790401795824 loss_input: 82.63846035358861
step: 9000 epoch: 3 loss: 23.44262604543387 loss_input: 82.71753791543779
step: 10000 epoch: 3 loss: 23.39735096047585 loss_input: 82.67371951159376
step: 11000 epoch: 3 loss: 23.371837821074827 loss_input: 82.57491328358466
step: 12000 epoch: 3 loss: 23.31655336747457 loss_input: 82.46694678519628
step: 13000 epoch: 3 loss: 23.285879854440378 loss_input: 82.47381395091003
step: 14000 epoch: 3 loss: 23.296971962951044 loss_input: 82.40857710864542
step: 15000 epoch: 3 loss: 23.289638309302024 loss_input: 82.35073379141261
Save loss: 23.248050446748735 Name: 3_train_model.pth
step: 0 epoch: 4 loss: 29.765478134155273 loss_input: 97.75347900390625
step: 1000 epoch: 4 loss: 22.583006441533627 loss_input: 81.91761961183347
step: 2000 epoch: 4 loss: 22.823396592185475 loss_input: 82.01899752028282
step: 3000 epoch: 4 loss: 22.710831352648277 loss_input: 82.10301827288039
step: 4000 epoch: 4 loss: 22.68460811647407 loss_input: 81.99718574689824
step: 5000 epoch: 4 loss: 22.673081796185013 loss_input: 82.26071028470088
step: 6000 epoch: 4 loss: 22.685976438056706 loss_input: 82.30977215263927
step: 7000 epoch: 4 loss: 22.6933499705943 loss_input: 82.31925329026657
step: 8000 epoch: 4 loss: 22.721626726631342 loss_input: 82.29775740465303
step: 9000 epoch: 4 loss: 22.705458507552674 loss_input: 82.26023635720163
step: 10000 epoch: 4 loss: 22.713928030271695 loss_input: 82.30745927482447
step: 11000 epoch: 4 loss: 22.709974313343604 loss_input: 82.22562749866312
step: 12000 epoch: 4 loss: 22.71161110462144 loss_input: 82.24082950973161
step: 13000 epoch: 4 loss: 22.686064130534998 loss_input: 82.23602102910654
step: 14000 epoch: 4 loss: 22.68334098870682 loss_input: 82.16508376755874
step: 15000 epoch: 4 loss: 22.67832382144423 loss_input: 82.23103266911112
Save loss: 22.679384616553783 Name: 4_train_model.pth
step: 0 epoch: 5 loss: 22.450159072875977 loss_input: 74.42230224609375
step: 1000 epoch: 5 loss: 22.643987299321772 loss_input: 82.76057188660948
step: 2000 epoch: 5 loss: 22.568030477225452 loss_input: 83.0176328766769
step: 3000 epoch: 5 loss: 22.494183700031456 loss_input: 82.97784983130623
step: 4000 epoch: 5 loss: 22.41834427922465 loss_input: 82.85243459642902
step: 5000 epoch: 5 loss: 22.391021062125922 loss_input: 82.53524872418095
step: 6000 epoch: 5 loss: 22.38934786044405 loss_input: 82.50434894558589
step: 7000 epoch: 5 loss: 22.351088274855083 loss_input: 82.4472338563799
step: 8000 epoch: 5 loss: 22.36482419742374 loss_input: 82.45288812165082
step: 9000 epoch: 5 loss: 22.30609508143996 loss_input: 82.19604842761612
step: 10000 epoch: 5 loss: 22.341686816301813 loss_input: 82.28538468784957
step: 11000 epoch: 5 loss: 22.33640082451812 loss_input: 82.22377238721373
step: 12000 epoch: 5 loss: 22.327704350756225 loss_input: 82.27294520093703
step: 13000 epoch: 5 loss: 22.32438662503098 loss_input: 82.2863246218515
step: 14000 epoch: 5 loss: 22.337060464381253 loss_input: 82.33550216732566
step: 15000 epoch: 5 loss: 22.29006346355525 loss_input: 82.2383984174818
Save loss: 22.25587961539626 Name: 5_train_model.pth
step: 0 epoch: 6 loss: 25.067489624023438 loss_input: 93.3343505859375
step: 1000 epoch: 6 loss: 22.118874549865723 loss_input: 82.48509912938624
step: 2000 epoch: 6 loss: 22.174183441840785 loss_input: 82.09274876111749
step: 3000 epoch: 6 loss: 21.98933117598623 loss_input: 82.40504261844359
step: 4000 epoch: 6 loss: 22.04223581636825 loss_input: 82.25418422616026
step: 5000 epoch: 6 loss: 22.035668056456 loss_input: 82.25525771310582
step: 6000 epoch: 6 loss: 21.907839000513107 loss_input: 81.9736992280258
step: 7000 epoch: 6 loss: 21.877401440675865 loss_input: 81.99825053766035
step: 8000 epoch: 6 loss: 21.871681715485277 loss_input: 82.07521252989129
step: 9000 epoch: 6 loss: 21.93801241728375 loss_input: 82.27370057976414
step: 10000 epoch: 6 loss: 21.95722624984053 loss_input: 82.21209481224729
step: 11000 epoch: 6 loss: 21.95921112526418 loss_input: 82.20985618849991
step: 12000 epoch: 6 loss: 21.946789282916455 loss_input: 82.14058554914531
step: 13000 epoch: 6 loss: 21.93539502446298 loss_input: 82.18555096873558
step: 14000 epoch: 6 loss: 21.940837594153464 loss_input: 82.26072586612116
step: 15000 epoch: 6 loss: 21.933900791552453 loss_input: 82.22163055340582
Save loss: 21.916805622935296 Name: 6_train_model.pth
step: 0 epoch: 7 loss: 26.88184356689453 loss_input: 76.47705078125
step: 1000 epoch: 7 loss: 21.719387891885642 loss_input: 82.35157993861607
step: 2000 epoch: 7 loss: 21.66963177094276 loss_input: 81.65265420268382
step: 3000 epoch: 7 loss: 21.761643157725093 loss_input: 81.75955268328526
step: 4000 epoch: 7 loss: 21.710780204757693 loss_input: 81.8350171215741
step: 5000 epoch: 7 loss: 21.70368313174371 loss_input: 82.06911266672446
step: 6000 epoch: 7 loss: 21.671173756330376 loss_input: 81.95417930833142
step: 7000 epoch: 7 loss: 21.666280075305362 loss_input: 81.96108051981692
step: 8000 epoch: 7 loss: 21.670987403358524 loss_input: 82.12347469322683
step: 9000 epoch: 7 loss: 21.65902395018497 loss_input: 82.2066215258309
step: 10000 epoch: 7 loss: 21.64671993179329 loss_input: 82.303494259949
step: 11000 epoch: 7 loss: 21.665723610201724 loss_input: 82.38230747999295
step: 12000 epoch: 7 loss: 21.638399160898643 loss_input: 82.26510553238403
step: 13000 epoch: 7 loss: 21.640758757645898 loss_input: 82.28617339306231
step: 14000 epoch: 7 loss: 21.640517533962136 loss_input: 82.17699241488332
step: 15000 epoch: 7 loss: 21.646202077135136 loss_input: 82.24664342852404
Save loss: 21.6288453733325 Name: 7_train_model.pth
step: 0 epoch: 8 loss: 23.165616989135742 loss_input: 68.51788330078125
step: 1000 epoch: 8 loss: 21.32212315834724 loss_input: 81.08710954572771
step: 2000 epoch: 8 loss: 21.44435062937472 loss_input: 81.71011323561852
step: 3000 epoch: 8 loss: 21.38177817744122 loss_input: 81.87946101706332
step: 4000 epoch: 8 loss: 21.496132003280767 loss_input: 82.39425754523283
step: 5000 epoch: 8 loss: 21.474864565737366 loss_input: 82.56941767164145
step: 6000 epoch: 8 loss: 21.455778887621108 loss_input: 82.48143987110547
step: 7000 epoch: 8 loss: 21.44287497655713 loss_input: 82.32969357997686
step: 8000 epoch: 8 loss: 21.36859126222713 loss_input: 82.30254231374154
step: 9000 epoch: 8 loss: 21.34210263685496 loss_input: 82.30244411048513
step: 10000 epoch: 8 loss: 21.344146550768507 loss_input: 82.30236646135191
step: 11000 epoch: 8 loss: 21.369201984246008 loss_input: 82.2736448619639
step: 12000 epoch: 8 loss: 21.370298997629344 loss_input: 82.2687950900332
step: 13000 epoch: 8 loss: 21.372559638786623 loss_input: 82.26423251020955
step: 14000 epoch: 8 loss: 21.378450893230177 loss_input: 82.27011080280677
step: 15000 epoch: 8 loss: 21.386871862726192 loss_input: 82.24644459330966
Save loss: 21.37500160267949 Name: 8_train_model.pth
step: 0 epoch: 9 loss: 25.34743881225586 loss_input: 64.2576904296875
step: 1000 epoch: 9 loss: 20.91533056958453 loss_input: 81.59391908140688
step: 2000 epoch: 9 loss: 21.100956177604253 loss_input: 82.00948558313617
step: 3000 epoch: 9 loss: 21.094307226882066 loss_input: 82.28852548824871
step: 4000 epoch: 9 loss: 21.143406697911818 loss_input: 82.7016996513811
step: 5000 epoch: 9 loss: 21.159922821954165 loss_input: 82.51054205662774
step: 6000 epoch: 9 loss: 21.155851198224063 loss_input: 82.45650050553098
step: 7000 epoch: 9 loss: 21.090950464592748 loss_input: 82.09852089001237
step: 8000 epoch: 9 loss: 21.154096585097214 loss_input: 82.17965526983687
step: 9000 epoch: 9 loss: 21.14583409345093 loss_input: 82.3149671873481
step: 10000 epoch: 9 loss: 21.143145294931337 loss_input: 82.30215761382846
step: 11000 epoch: 9 loss: 21.140567437593162 loss_input: 82.31231118548882
step: 12000 epoch: 9 loss: 21.141362217145904 loss_input: 82.26933092387972
step: 13000 epoch: 9 loss: 21.14169673205944 loss_input: 82.18167751087206
step: 14000 epoch: 9 loss: 21.13685764134692 loss_input: 82.1536410642125
step: 15000 epoch: 9 loss: 21.147185117481122 loss_input: 82.20988217891593
Save loss: 21.157277643591165 Name: 9_train_model.pth
step: 0 epoch: 10 loss: 40.42790985107422 loss_input: 74.583251953125
step: 1000 epoch: 10 loss: 20.937460343439977 loss_input: 80.1667654245169
step: 2000 epoch: 10 loss: 20.877144217789024 loss_input: 81.27080258698776
step: 3000 epoch: 10 loss: 20.91000119514046 loss_input: 81.74783712639406
step: 4000 epoch: 10 loss: 21.009095447714763 loss_input: 82.14263606339627
step: 5000 epoch: 10 loss: 20.926371380463287 loss_input: 82.03576552755855
step: 6000 epoch: 10 loss: 20.888529565687517 loss_input: 82.0103583708542
step: 7000 epoch: 10 loss: 20.910260311179016 loss_input: 82.30014658376092
step: 8000 epoch: 10 loss: 20.9287624207754 loss_input: 82.11729799796754
step: 9000 epoch: 10 loss: 20.901833147780653 loss_input: 82.06153112707528
step: 10000 epoch: 10 loss: 20.9045033110653 loss_input: 82.03446033570471
step: 11000 epoch: 10 loss: 20.922831314713854 loss_input: 82.14266407688079
step: 12000 epoch: 10 loss: 20.954274666546763 loss_input: 82.1229545009026
step: 13000 epoch: 10 loss: 20.9602913639012 loss_input: 82.18875853262189
step: 14000 epoch: 10 loss: 20.98225554612081 loss_input: 82.25188623960594
step: 15000 epoch: 10 loss: 20.96675032846499 loss_input: 82.1980422903447
Save loss: 20.963989174574614 Name: 10_train_model.pth
step: 0 epoch: 11 loss: 18.099246978759766 loss_input: 68.42327880859375
step: 1000 epoch: 11 loss: 20.51586838130589 loss_input: 81.51306634039788
step: 2000 epoch: 11 loss: 20.690540571560685 loss_input: 82.0083065461898
step: 3000 epoch: 11 loss: 20.770093233177796 loss_input: 81.90643554606147
step: 4000 epoch: 11 loss: 20.84931015831266 loss_input: 81.83759698198008
step: 5000 epoch: 11 loss: 20.856887972037857 loss_input: 82.15127774005745
step: 6000 epoch: 11 loss: 20.876210585055283 loss_input: 82.07399265242903
step: 7000 epoch: 11 loss: 20.83115518639691 loss_input: 81.92476107975088
step: 8000 epoch: 11 loss: 20.797193931588648 loss_input: 82.05971648868598
step: 9000 epoch: 11 loss: 20.782851043349837 loss_input: 81.98257791099383
step: 10000 epoch: 11 loss: 20.76467403003352 loss_input: 81.94743593267626
step: 11000 epoch: 11 loss: 20.767590727700764 loss_input: 81.98038846832462
step: 12000 epoch: 11 loss: 20.78181135383271 loss_input: 82.03463630940098
step: 13000 epoch: 11 loss: 20.7931632701823 loss_input: 82.10391244506131
step: 14000 epoch: 11 loss: 20.77476928823463 loss_input: 82.1217809480545
step: 15000 epoch: 11 loss: 20.770305954339577 loss_input: 82.14541176584322
Save loss: 20.786398529708386 Name: 11_train_model.pth
step: 0 epoch: 12 loss: 23.043180465698242 loss_input: 69.19482421875
step: 1000 epoch: 12 loss: 20.713216669671425 loss_input: 82.59951968197818
step: 2000 epoch: 12 loss: 20.557738158537234 loss_input: 82.10450829272864
step: 3000 epoch: 12 loss: 20.592502310529465 loss_input: 82.23793680101424
step: 4000 epoch: 12 loss: 20.58257133583521 loss_input: 82.35495812021115
step: 5000 epoch: 12 loss: 20.631041047192173 loss_input: 82.3240367185352
step: 6000 epoch: 12 loss: 20.630917252113253 loss_input: 82.21164083329862
step: 7000 epoch: 12 loss: 20.612739300697196 loss_input: 82.13680396034384
step: 8000 epoch: 12 loss: 20.623276659733445 loss_input: 82.06648002465268
step: 9000 epoch: 12 loss: 20.603564616164 loss_input: 81.97179652971501
step: 10000 epoch: 12 loss: 20.60288892318196 loss_input: 82.07899963787801
step: 11000 epoch: 12 loss: 20.626904319908476 loss_input: 82.1003992479288
step: 12000 epoch: 12 loss: 20.634583426797285 loss_input: 82.14622033348621
step: 13000 epoch: 12 loss: 20.654692711018477 loss_input: 82.25286977905996
step: 14000 epoch: 12 loss: 20.65622919178479 loss_input: 82.27357649328061
step: 15000 epoch: 12 loss: 20.65471919590088 loss_input: 82.32305157113875
Save loss: 20.648055327132344 Name: 12_train_model.pth
step: 0 epoch: 13 loss: 23.618125915527344 loss_input: 82.488525390625
step: 1000 epoch: 13 loss: 20.58335451408104 loss_input: 82.37714610828624
step: 2000 epoch: 13 loss: 20.324120449340683 loss_input: 81.83245477480986
step: 3000 epoch: 13 loss: 20.502707053327196 loss_input: 82.26437771475264
step: 4000 epoch: 13 loss: 20.40915193083405 loss_input: 81.83494106026716
step: 5000 epoch: 13 loss: 20.45617560590894 loss_input: 82.13475791169891
step: 6000 epoch: 13 loss: 20.423757263708662 loss_input: 82.07542348492048
step: 7000 epoch: 13 loss: 20.43521934542515 loss_input: 82.03626700963757
step: 8000 epoch: 13 loss: 20.45970069043503 loss_input: 82.10428191715293
step: 9000 epoch: 13 loss: 20.495683904833665 loss_input: 82.15653417523922
step: 10000 epoch: 13 loss: 20.4824017861428 loss_input: 82.13774142605271
step: 11000 epoch: 13 loss: 20.48493171533599 loss_input: 82.0756508263986
step: 12000 epoch: 13 loss: 20.499214357916944 loss_input: 82.1570456032554
step: 13000 epoch: 13 loss: 20.484367820888508 loss_input: 82.09367227535982
step: 14000 epoch: 13 loss: 20.488210771519935 loss_input: 82.10118921820875
step: 15000 epoch: 13 loss: 20.502000066202708 loss_input: 82.1655238853217
Save loss: 20.50581438946724 Name: 13_train_model.pth
step: 0 epoch: 14 loss: 26.01840591430664 loss_input: 83.60986328125
step: 1000 epoch: 14 loss: 20.125357215816564 loss_input: 82.74498511742163
step: 2000 epoch: 14 loss: 20.128091245934346 loss_input: 82.3039544070738
step: 3000 epoch: 14 loss: 20.259047121335886 loss_input: 82.71295021613889
step: 4000 epoch: 14 loss: 20.3449046419311 loss_input: 82.53648009201314
step: 5000 epoch: 14 loss: 20.324058035473136 loss_input: 82.22304386778895
step: 6000 epoch: 14 loss: 20.302142037170924 loss_input: 81.99491506257746
step: 7000 epoch: 14 loss: 20.286234370232854 loss_input: 81.97606344322463
step: 8000 epoch: 14 loss: 20.305632350415294 loss_input: 82.06502968256898
step: 9000 epoch: 14 loss: 20.329083932981057 loss_input: 81.98981107540786
step: 10000 epoch: 14 loss: 20.355905339212708 loss_input: 82.17439413285234
step: 11000 epoch: 14 loss: 20.395057942366428 loss_input: 82.20433471779555
step: 12000 epoch: 14 loss: 20.414488663843063 loss_input: 82.2573702099939
step: 13000 epoch: 14 loss: 20.407462445380787 loss_input: 82.25157888620947
step: 14000 epoch: 14 loss: 20.42224856405869 loss_input: 82.27312518797486
step: 15000 epoch: 14 loss: 20.41556279839345 loss_input: 82.26059369072661
Save loss: 20.395687653779984 Name: 14_train_model.pth
step: 0 epoch: 15 loss: 20.085102081298828 loss_input: 78.02593994140625
step: 1000 epoch: 15 loss: 20.228282050533846 loss_input: 82.28183736429585
step: 2000 epoch: 15 loss: 20.243686148192154 loss_input: 82.70789776010432
step: 3000 epoch: 15 loss: 20.17370419182884 loss_input: 82.29985606197674
step: 4000 epoch: 15 loss: 20.105566763216423 loss_input: 82.32411216348744
step: 5000 epoch: 15 loss: 20.121496166236113 loss_input: 82.19219608226793
step: 6000 epoch: 15 loss: 20.120926485640112 loss_input: 82.06431604254108
step: 7000 epoch: 15 loss: 20.16155669543083 loss_input: 82.19679594809558
step: 8000 epoch: 15 loss: 20.15935696808789 loss_input: 81.99205258339289
step: 9000 epoch: 15 loss: 20.188732579739515 loss_input: 82.22926037460681
step: 10000 epoch: 15 loss: 20.221298776356154 loss_input: 82.29036718520531
step: 11000 epoch: 15 loss: 20.20659930430134 loss_input: 82.29043047866564
step: 12000 epoch: 15 loss: 20.21805374092504 loss_input: 82.36068173009508
step: 13000 epoch: 15 loss: 20.23789550991996 loss_input: 82.36272865203277
step: 14000 epoch: 15 loss: 20.24839687318463 loss_input: 82.32730798508115
step: 15000 epoch: 15 loss: 20.263819622124092 loss_input: 82.261680719495
Save loss: 20.274457624897362 Name: 15_train_model.pth
step: 0 epoch: 16 loss: 26.992124557495117 loss_input: 111.9390869140625
step: 1000 epoch: 16 loss: 20.377987340018226 loss_input: 83.72651652546672
step: 2000 epoch: 16 loss: 20.192685492809627 loss_input: 82.91506663660357
step: 3000 epoch: 16 loss: 20.24761782388455 loss_input: 82.41098712945295
step: 4000 epoch: 16 loss: 20.242871290682196 loss_input: 82.3384158690552
step: 5000 epoch: 16 loss: 20.18360475434515 loss_input: 82.24285282103736
step: 6000 epoch: 16 loss: 20.20593955528337 loss_input: 82.1665920771831
step: 7000 epoch: 16 loss: 20.20861291401796 loss_input: 82.24095066845919
step: 8000 epoch: 16 loss: 20.19900414502974 loss_input: 82.2836818172997
step: 9000 epoch: 16 loss: 20.201972441572096 loss_input: 82.34981278257494
step: 10000 epoch: 16 loss: 20.191023830461116 loss_input: 82.43829883979376
step: 11000 epoch: 16 loss: 20.176063132886398 loss_input: 82.52984363371085
step: 12000 epoch: 16 loss: 20.195408538841882 loss_input: 82.48990629259899
step: 13000 epoch: 16 loss: 20.18675552934016 loss_input: 82.40974387656027
step: 14000 epoch: 16 loss: 20.186635688597555 loss_input: 82.40711900879847
step: 15000 epoch: 16 loss: 20.179787546227388 loss_input: 82.32437346380684
Save loss: 20.172558823168277 Name: 16_train_model.pth
step: 0 epoch: 17 loss: 21.758481979370117 loss_input: 80.6263427734375
step: 1000 epoch: 17 loss: 19.984838620527878 loss_input: 82.10143799072021
step: 2000 epoch: 17 loss: 20.09601418868355 loss_input: 82.57094328812157
step: 3000 epoch: 17 loss: 20.226820019394985 loss_input: 82.81997486433559
step: 4000 epoch: 17 loss: 20.23056569048179 loss_input: 82.56895827007604
step: 5000 epoch: 17 loss: 20.174477649388184 loss_input: 82.28580337399318
step: 6000 epoch: 17 loss: 20.109284642894472 loss_input: 82.19511715902168
step: 7000 epoch: 17 loss: 20.154258271146375 loss_input: 82.47060689502504
step: 8000 epoch: 17 loss: 20.144766826627254 loss_input: 82.49847510516264
step: 9000 epoch: 17 loss: 20.132235078702514 loss_input: 82.42897898090533
step: 10000 epoch: 17 loss: 20.10742155626623 loss_input: 82.28322123232013
step: 11000 epoch: 17 loss: 20.101285620847946 loss_input: 82.2949436514738
step: 12000 epoch: 17 loss: 20.104801760346838 loss_input: 82.37881425734054
step: 13000 epoch: 17 loss: 20.123287592821054 loss_input: 82.33654826938643
step: 14000 epoch: 17 loss: 20.099320792307232 loss_input: 82.28555888760457
step: 15000 epoch: 17 loss: 20.09080249021454 loss_input: 82.25434007117624
Save loss: 20.077778635561465 Name: 17_train_model.pth
step: 0 epoch: 18 loss: 15.62985610961914 loss_input: 61.01324462890625
step: 1000 epoch: 18 loss: 19.78396589391596 loss_input: 81.29465541782436
step: 2000 epoch: 18 loss: 19.782231413799785 loss_input: 81.5819493512521
step: 3000 epoch: 18 loss: 19.867531938657727 loss_input: 81.84324371937869
step: 4000 epoch: 18 loss: 19.865860586135394 loss_input: 82.03194735068674
step: 5000 epoch: 18 loss: 19.966833632937718 loss_input: 82.21044775419917
step: 6000 epoch: 18 loss: 20.02909825774277 loss_input: 82.2927589359293
step: 7000 epoch: 18 loss: 20.044752578601855 loss_input: 82.38165133252448
step: 8000 epoch: 18 loss: 20.042438715133887 loss_input: 82.51786184960523
step: 9000 epoch: 18 loss: 20.055404507283463 loss_input: 82.42006512893967
step: 10000 epoch: 18 loss: 20.04754784226167 loss_input: 82.36948124035253
step: 11000 epoch: 18 loss: 20.042398374954708 loss_input: 82.29409538430633
step: 12000 epoch: 18 loss: 20.039214094324258 loss_input: 82.45415535542122
step: 13000 epoch: 18 loss: 20.01738999728175 loss_input: 82.31221327419675
step: 14000 epoch: 18 loss: 20.02172436195479 loss_input: 82.34826218118907
step: 15000 epoch: 18 loss: 20.007923180576515 loss_input: 82.28078723381331
Save loss: 20.004509253561498 Name: 18_train_model.pth
step: 0 epoch: 19 loss: 20.65306854248047 loss_input: 88.1015625
step: 1000 epoch: 19 loss: 20.084584802538007 loss_input: 82.57932692307692
step: 2000 epoch: 19 loss: 20.104916437216726 loss_input: 82.4002641318501
step: 3000 epoch: 19 loss: 20.005688833658077 loss_input: 82.0578271801652
step: 4000 epoch: 19 loss: 19.839986400466 loss_input: 81.9474499356118
step: 5000 epoch: 19 loss: 19.824588058996476 loss_input: 81.86653467646315
step: 6000 epoch: 19 loss: 19.802392064799985 loss_input: 82.06095261995722
step: 7000 epoch: 19 loss: 19.812614188570922 loss_input: 82.08993957894408
step: 8000 epoch: 19 loss: 19.86085167540236 loss_input: 82.19998819269905
step: 9000 epoch: 19 loss: 19.831921686160406 loss_input: 82.14056830463933
step: 10000 epoch: 19 loss: 19.86747198545412 loss_input: 82.07697928937576
step: 11000 epoch: 19 loss: 19.88188046609778 loss_input: 82.0734680580796
step: 12000 epoch: 19 loss: 19.87787073229305 loss_input: 82.16117257867671
step: 13000 epoch: 19 loss: 19.893355969272847 loss_input: 82.26303924731901
step: 14000 epoch: 19 loss: 19.90228661604672 loss_input: 82.26850052702709
step: 15000 epoch: 19 loss: 19.88274671312857 loss_input: 82.14908730205747
Save loss: 19.907506893992423 Name: 19_train_model.pth
step: 0 epoch: 20 loss: 15.248661041259766 loss_input: 76.3060302734375
step: 1000 epoch: 20 loss: 19.857391891422328 loss_input: 82.60955572747565
step: 2000 epoch: 20 loss: 19.852886016460612 loss_input: 83.1146809407796
step: 3000 epoch: 20 loss: 19.812800414718733 loss_input: 82.8516005122316
step: 4000 epoch: 20 loss: 19.84407807898146 loss_input: 82.7211799039986
step: 5000 epoch: 20 loss: 19.768043074219783 loss_input: 82.5458961674462
step: 6000 epoch: 20 loss: 19.769340932061326 loss_input: 82.44910630129354
step: 7000 epoch: 20 loss: 19.776948431086122 loss_input: 82.45632454640966
step: 8000 epoch: 20 loss: 19.76589239497376 loss_input: 82.27095256586578
step: 9000 epoch: 20 loss: 19.814085078231493 loss_input: 82.37001682294633
step: 10000 epoch: 20 loss: 19.8274317717936 loss_input: 82.32373156117005
step: 11000 epoch: 20 loss: 19.834715569347654 loss_input: 82.32969889256339
step: 12000 epoch: 20 loss: 19.83244461552738 loss_input: 82.2716930317249
step: 13000 epoch: 20 loss: 19.83936837064093 loss_input: 82.36289125596107
step: 14000 epoch: 20 loss: 19.84297979597483 loss_input: 82.28447608356518
step: 15000 epoch: 20 loss: 19.825167761159875 loss_input: 82.22011378440656
Save loss: 19.829966906160116 Name: 20_train_model.pth
step: 0 epoch: 21 loss: 15.998072624206543 loss_input: 74.6903076171875
step: 1000 epoch: 21 loss: 19.64447875742193 loss_input: 81.68935684676651
step: 2000 epoch: 21 loss: 19.816703251395925 loss_input: 82.32702035822909
step: 3000 epoch: 21 loss: 19.750928616611134 loss_input: 82.08947837293168
step: 4000 epoch: 21 loss: 19.732843898648294 loss_input: 82.23904810235429
step: 5000 epoch: 21 loss: 19.688400318135837 loss_input: 82.11373283204688
step: 6000 epoch: 21 loss: 19.69494291020123 loss_input: 82.05916064160205
step: 7000 epoch: 21 loss: 19.70532469530818 loss_input: 82.05812111767236
step: 8000 epoch: 21 loss: 19.71599524182955 loss_input: 82.12399974356232
step: 9000 epoch: 21 loss: 19.70405121170644 loss_input: 82.09108129695659
step: 10000 epoch: 21 loss: 19.727647073244334 loss_input: 82.12653236019172
step: 11000 epoch: 21 loss: 19.719435112442323 loss_input: 82.08373378188098
step: 12000 epoch: 21 loss: 19.73344281784406 loss_input: 82.13864723919491
step: 13000 epoch: 21 loss: 19.750355057253874 loss_input: 82.25772934364875
step: 14000 epoch: 21 loss: 19.77358051266264 loss_input: 82.31215706795217
step: 15000 epoch: 21 loss: 19.76019040464314 loss_input: 82.23481825251363
Save loss: 19.767116904318332 Name: 21_train_model.pth
step: 0 epoch: 22 loss: 18.974388122558594 loss_input: 104.1466064453125
step: 1000 epoch: 22 loss: 19.758222609490424 loss_input: 82.32156161709385
step: 2000 epoch: 22 loss: 19.784861164769787 loss_input: 82.11991480456061
step: 3000 epoch: 22 loss: 19.699614572350242 loss_input: 82.17798280700053
step: 4000 epoch: 22 loss: 19.750494006275385 loss_input: 81.92695399148259
step: 5000 epoch: 22 loss: 19.70368871400891 loss_input: 82.05477872931273
step: 6000 epoch: 22 loss: 19.67586083190478 loss_input: 82.01891297536022
step: 7000 epoch: 22 loss: 19.67252697322798 loss_input: 81.95786080852847
step: 8000 epoch: 22 loss: 19.666083256463203 loss_input: 82.00478999725864
step: 9000 epoch: 22 loss: 19.63353206149579 loss_input: 81.98784259160007
step: 10000 epoch: 22 loss: 19.627901871005793 loss_input: 82.05323322037913
step: 11000 epoch: 22 loss: 19.637958756751033 loss_input: 82.11356896576518
step: 12000 epoch: 22 loss: 19.66849333685087 loss_input: 82.12589726918102
step: 13000 epoch: 22 loss: 19.684195390912848 loss_input: 82.17766910996329
step: 14000 epoch: 22 loss: 19.659984784538036 loss_input: 82.12838368252017
step: 15000 epoch: 22 loss: 19.69126831162064 loss_input: 82.17553602302164
Save loss: 19.699878420814873 Name: 22_train_model.pth
step: 0 epoch: 23 loss: 22.8159236907959 loss_input: 114.84442138671875
step: 1000 epoch: 23 loss: 19.77077639996112 loss_input: 83.55074222652348
step: 2000 epoch: 23 loss: 19.674034376015726 loss_input: 82.82967543327945
step: 3000 epoch: 23 loss: 19.717796629804326 loss_input: 83.32097571073314
step: 4000 epoch: 23 loss: 19.666515725042128 loss_input: 82.90537087102736
step: 5000 epoch: 23 loss: 19.694595479936606 loss_input: 82.61068494308951
step: 6000 epoch: 23 loss: 19.63015918663354 loss_input: 82.26437830023121
step: 7000 epoch: 23 loss: 19.59740311771508 loss_input: 82.23219266841623
step: 8000 epoch: 23 loss: 19.617567068814427 loss_input: 82.13574825973902
step: 9000 epoch: 23 loss: 19.61715430517274 loss_input: 82.13507012946913
step: 10000 epoch: 23 loss: 19.610761162567442 loss_input: 82.07088101614643
step: 11000 epoch: 23 loss: 19.61171965178181 loss_input: 82.07285206960056
step: 12000 epoch: 23 loss: 19.6041793118774 loss_input: 81.96346482133163
step: 13000 epoch: 23 loss: 19.629374505152988 loss_input: 82.14810939084914
step: 14000 epoch: 23 loss: 19.6338953563515 loss_input: 82.08117525819863
step: 15000 epoch: 23 loss: 19.66071636506251 loss_input: 82.25370889987542
Save loss: 19.645041290044784 Name: 23_train_model.pth
step: 0 epoch: 24 loss: 21.201936721801758 loss_input: 79.6612548828125
step: 1000 epoch: 24 loss: 19.505222364858195 loss_input: 82.06576199679228
step: 2000 epoch: 24 loss: 19.51492784095966 loss_input: 81.92344892007121
step: 3000 epoch: 24 loss: 19.50516452077467 loss_input: 81.69452286656401
step: 4000 epoch: 24 loss: 19.47942615169133 loss_input: 81.6157064707212
step: 5000 epoch: 24 loss: 19.474803427032793 loss_input: 81.68104353982719
step: 6000 epoch: 24 loss: 19.4880327341696 loss_input: 81.59642909856821
step: 7000 epoch: 24 loss: 19.485765899935547 loss_input: 81.7146589793813
step: 8000 epoch: 24 loss: 19.510558806722006 loss_input: 81.9183330995979
step: 9000 epoch: 24 loss: 19.532991961391353 loss_input: 81.95007383212847
step: 10000 epoch: 24 loss: 19.52476971719923 loss_input: 81.9528099253063
step: 11000 epoch: 24 loss: 19.553810548114836 loss_input: 82.07063443118275
step: 12000 epoch: 24 loss: 19.56734770666052 loss_input: 82.14420874167875
step: 13000 epoch: 24 loss: 19.560721127274093 loss_input: 82.09233998038312
step: 14000 epoch: 24 loss: 19.562009527533235 loss_input: 82.12930415771781
step: 15000 epoch: 24 loss: 19.553251576085113 loss_input: 82.15171062570438
Save loss: 19.57834560996294 Name: 24_train_model.pth
step: 0 epoch: 25 loss: 23.226856231689453 loss_input: 70.17962646484375
step: 1000 epoch: 25 loss: 19.417693504444014 loss_input: 83.76526214264251
step: 2000 epoch: 25 loss: 19.4940178033294 loss_input: 83.00696505385002
step: 3000 epoch: 25 loss: 19.598188740616838 loss_input: 82.84168279762865
step: 4000 epoch: 25 loss: 19.530912521331796 loss_input: 82.62321559502702
step: 5000 epoch: 25 loss: 19.513298998353864 loss_input: 82.58254186565031
step: 6000 epoch: 25 loss: 19.48831392887969 loss_input: 82.53329588297784
step: 7000 epoch: 25 loss: 19.494086615784887 loss_input: 82.54791067968247
step: 8000 epoch: 25 loss: 19.501477066419554 loss_input: 82.61814218413129
step: 9000 epoch: 25 loss: 19.484382095767078 loss_input: 82.55643135870103
step: 10000 epoch: 25 loss: 19.512291401389266 loss_input: 82.37777814015473
step: 11000 epoch: 25 loss: 19.532283398403102 loss_input: 82.42711956827611
step: 12000 epoch: 25 loss: 19.531826505302618 loss_input: 82.35769432849183
step: 13000 epoch: 25 loss: 19.539849425983306 loss_input: 82.27158337579802
step: 14000 epoch: 25 loss: 19.55380122386237 loss_input: 82.31367941143155
step: 15000 epoch: 25 loss: 19.535811620524356 loss_input: 82.1879930498123
Save loss: 19.540242795303463 Name: 25_train_model.pth
step: 0 epoch: 26 loss: 16.424442291259766 loss_input: 88.72772216796875
step: 1000 epoch: 26 loss: 19.104647069067866 loss_input: 82.54804747254698
step: 2000 epoch: 26 loss: 19.24029307934953 loss_input: 82.26611120709177
step: 3000 epoch: 26 loss: 19.351228388735787 loss_input: 82.35127341179242
step: 4000 epoch: 26 loss: 19.39125367457555 loss_input: 82.11480868491373
step: 5000 epoch: 26 loss: 19.3545359199797 loss_input: 82.04248272659922
step: 6000 epoch: 26 loss: 19.37359428795114 loss_input: 82.2429159043968
step: 7000 epoch: 26 loss: 19.388990535035916 loss_input: 82.28755100589704
step: 8000 epoch: 26 loss: 19.38492247933463 loss_input: 82.20239606432253
step: 9000 epoch: 26 loss: 19.424660326944245 loss_input: 82.1917029699608
step: 10000 epoch: 26 loss: 19.44408549898661 loss_input: 82.20995668377498
step: 11000 epoch: 26 loss: 19.478436958637033 loss_input: 82.19883261566953
step: 12000 epoch: 26 loss: 19.46786765507505 loss_input: 82.24212238091488
step: 13000 epoch: 26 loss: 19.476239213961087 loss_input: 82.23048606856715
step: 14000 epoch: 26 loss: 19.469518375297962 loss_input: 82.24069240241211
step: 15000 epoch: 26 loss: 19.492501934785285 loss_input: 82.26491703124739
Save loss: 19.47438513816893 Name: 26_train_model.pth
step: 0 epoch: 27 loss: 18.377010345458984 loss_input: 63.99151611328125
step: 1000 epoch: 27 loss: 19.336114862939336 loss_input: 82.36684799575424
step: 2000 epoch: 27 loss: 19.463771303673497 loss_input: 82.14395429848553
step: 3000 epoch: 27 loss: 19.49382979231888 loss_input: 82.61432999302967
step: 4000 epoch: 27 loss: 19.422193133929348 loss_input: 82.26340909279516
step: 5000 epoch: 27 loss: 19.524889900216674 loss_input: 82.28713760421743
step: 6000 epoch: 27 loss: 19.50966022682476 loss_input: 82.2959256546435
step: 7000 epoch: 27 loss: 19.47818538594665 loss_input: 82.34511529219319
step: 8000 epoch: 27 loss: 19.4297722486716 loss_input: 82.2487981925233
step: 9000 epoch: 27 loss: 19.448305085796395 loss_input: 82.26800048882373
step: 10000 epoch: 27 loss: 19.46987340276497 loss_input: 82.350151551007
step: 11000 epoch: 27 loss: 19.474905620931594 loss_input: 82.45698338059466
step: 12000 epoch: 27 loss: 19.459669516351003 loss_input: 82.37801145762268
step: 13000 epoch: 27 loss: 19.456089883572815 loss_input: 82.35552917954628
step: 14000 epoch: 27 loss: 19.452101256011105 loss_input: 82.32167524794546
step: 15000 epoch: 27 loss: 19.450234339337502 loss_input: 82.28101282912519
Save loss: 19.44365719819069 Name: 27_train_model.pth
step: 0 epoch: 28 loss: 17.326324462890625 loss_input: 89.49102783203125
step: 1000 epoch: 28 loss: 19.486215179378576 loss_input: 82.55844948508523
step: 2000 epoch: 28 loss: 19.401659088811535 loss_input: 82.42117585616371
step: 3000 epoch: 28 loss: 19.310755721730654 loss_input: 82.07649712465637
step: 4000 epoch: 28 loss: 19.31178526412365 loss_input: 82.06065259197896
step: 5000 epoch: 28 loss: 19.299657925203594 loss_input: 82.15852873126546
step: 6000 epoch: 28 loss: 19.271085889552797 loss_input: 82.06756648753527
step: 7000 epoch: 28 loss: 19.280580560746593 loss_input: 82.03318993457128
step: 8000 epoch: 28 loss: 19.255358257229336 loss_input: 81.88266006849241
step: 9000 epoch: 28 loss: 19.30611401485769 loss_input: 81.98311494713478
step: 10000 epoch: 28 loss: 19.319563448661544 loss_input: 82.12088111867524
step: 11000 epoch: 28 loss: 19.33289623685278 loss_input: 82.06023541316911
step: 12000 epoch: 28 loss: 19.305610674896318 loss_input: 82.05781843415718
step: 13000 epoch: 28 loss: 19.329436171651757 loss_input: 82.1304369315341
step: 14000 epoch: 28 loss: 19.359612515190484 loss_input: 82.1930877094856
step: 15000 epoch: 28 loss: 19.371945653849544 loss_input: 82.18738326380455
Save loss: 19.38958236993849 Name: 28_train_model.pth
step: 0 epoch: 29 loss: 18.186697006225586 loss_input: 83.385498046875
step: 1000 epoch: 29 loss: 19.218056848832777 loss_input: 81.96650974757664
step: 2000 epoch: 29 loss: 19.247578024208874 loss_input: 82.21236022003647
step: 3000 epoch: 29 loss: 19.235514585354533 loss_input: 82.00198412052754
step: 4000 epoch: 29 loss: 19.282066492639878 loss_input: 82.05941716780278
step: 5000 epoch: 29 loss: 19.331010518515498 loss_input: 81.87935557419766
step: 6000 epoch: 29 loss: 19.31430462999476 loss_input: 82.10959019444024
step: 7000 epoch: 29 loss: 19.319037107582893 loss_input: 82.07561743237294
step: 8000 epoch: 29 loss: 19.382762629126717 loss_input: 82.22297862028721
step: 9000 epoch: 29 loss: 19.35242570541843 loss_input: 82.17417071117532
step: 10000 epoch: 29 loss: 19.33278820612659 loss_input: 82.15906417170783
step: 11000 epoch: 29 loss: 19.351011281186434 loss_input: 82.17651865411028
step: 12000 epoch: 29 loss: 19.324484071516213 loss_input: 82.12533657066663
step: 13000 epoch: 29 loss: 19.337342611909527 loss_input: 82.12427670452634
step: 14000 epoch: 29 loss: 19.32663346280303 loss_input: 82.02861102398238
step: 15000 epoch: 29 loss: 19.339980552231626 loss_input: 82.16641310826674
Save loss: 19.333682137578727 Name: 29_train_model.pth
step: 0 epoch: 30 loss: 24.572612762451172 loss_input: 105.561279296875
step: 1000 epoch: 30 loss: 19.172302070792977 loss_input: 81.16899537230348
step: 2000 epoch: 30 loss: 19.11123476619425 loss_input: 81.32945337633917
step: 3000 epoch: 30 loss: 19.29504924470367 loss_input: 81.61161558614576
step: 4000 epoch: 30 loss: 19.365955096666468 loss_input: 81.9257068972503
step: 5000 epoch: 30 loss: 19.303095851891328 loss_input: 81.9536386545933
step: 6000 epoch: 30 loss: 19.2837513618679 loss_input: 81.87122946956757
step: 7000 epoch: 30 loss: 19.263773117792844 loss_input: 81.8276940836019
step: 8000 epoch: 30 loss: 19.27585464494703 loss_input: 81.95412263988241
step: 9000 epoch: 30 loss: 19.28198234092764 loss_input: 81.86137895485571
step: 10000 epoch: 30 loss: 19.268631303945718 loss_input: 81.94533650882958
step: 11000 epoch: 30 loss: 19.285005465256887 loss_input: 82.13639863860921
step: 12000 epoch: 30 loss: 19.2712482645575 loss_input: 82.03352074582978
step: 13000 epoch: 30 loss: 19.276148731750155 loss_input: 82.10061702547821
step: 14000 epoch: 30 loss: 19.290659468205142 loss_input: 82.24220042545092
step: 15000 epoch: 30 loss: 19.2939731997654 loss_input: 82.21653901865527
Save loss: 19.304107328474522 Name: 30_train_model.pth
step: 0 epoch: 31 loss: 19.519330978393555 loss_input: 90.1033935546875
step: 1000 epoch: 31 loss: 19.304117849656752 loss_input: 82.32191447468547
step: 2000 epoch: 31 loss: 19.440054565831936 loss_input: 83.62322714375235
step: 3000 epoch: 31 loss: 19.288409541980776 loss_input: 82.89960808962117
step: 4000 epoch: 31 loss: 19.279899499202426 loss_input: 82.71201311305474
step: 5000 epoch: 31 loss: 19.238990377793428 loss_input: 82.59714735519692
step: 6000 epoch: 31 loss: 19.207214834888347 loss_input: 82.35520806143312
step: 7000 epoch: 31 loss: 19.20916192123948 loss_input: 82.25529933537675
step: 8000 epoch: 31 loss: 19.230901817875555 loss_input: 82.32748006108612
step: 9000 epoch: 31 loss: 19.217863308854955 loss_input: 82.36404784098424
step: 10000 epoch: 31 loss: 19.234596680526842 loss_input: 82.42976077758435
step: 11000 epoch: 31 loss: 19.240622131036268 loss_input: 82.44756835404878
step: 12000 epoch: 31 loss: 19.23968458247179 loss_input: 82.39114791581495
step: 13000 epoch: 31 loss: 19.244223718963745 loss_input: 82.31956698474366
step: 14000 epoch: 31 loss: 19.269999300085743 loss_input: 82.18937947390616
step: 15000 epoch: 31 loss: 19.28049392975471 loss_input: 82.15231954100196
Save loss: 19.26580860427022 Name: 31_train_model.pth
step: 0 epoch: 32 loss: 25.407001495361328 loss_input: 69.953369140625
step: 1000 epoch: 32 loss: 19.165645258767263 loss_input: 83.1810156396338
step: 2000 epoch: 32 loss: 19.16510948593887 loss_input: 82.69814854535623
step: 3000 epoch: 32 loss: 19.245062896705637 loss_input: 82.92657283591016
step: 4000 epoch: 32 loss: 19.218446339466844 loss_input: 82.70425952776942
step: 5000 epoch: 32 loss: 19.24672511281359 loss_input: 82.75591793262441
step: 6000 epoch: 32 loss: 19.248921092322142 loss_input: 82.6529473888141
step: 7000 epoch: 32 loss: 19.257338819665886 loss_input: 82.45078560380045
step: 8000 epoch: 32 loss: 19.2685114015804 loss_input: 82.6040359838443
step: 9000 epoch: 32 loss: 19.256782556478083 loss_input: 82.49377517352673
step: 10000 epoch: 32 loss: 19.26843631983924 loss_input: 82.45223977968413
step: 11000 epoch: 32 loss: 19.24139642758799 loss_input: 82.19773033217683
step: 12000 epoch: 32 loss: 19.26117048795179 loss_input: 82.30432209771094
step: 13000 epoch: 32 loss: 19.236372970359234 loss_input: 82.35097490810503
step: 14000 epoch: 32 loss: 19.226756472117934 loss_input: 82.30704654083023
step: 15000 epoch: 32 loss: 19.215363049124107 loss_input: 82.26699877722996
Save loss: 19.208827104300262 Name: 32_train_model.pth
step: 0 epoch: 33 loss: 20.855159759521484 loss_input: 59.38494873046875
step: 1000 epoch: 33 loss: 19.279576151521056 loss_input: 82.80964159131884
step: 2000 epoch: 33 loss: 19.101072555896582 loss_input: 82.07215172931113
step: 3000 epoch: 33 loss: 19.110822656797353 loss_input: 82.14596164071611
step: 4000 epoch: 33 loss: 19.193202084167336 loss_input: 82.43323893452906
step: 5000 epoch: 33 loss: 19.182642206528786 loss_input: 82.15782962792207
step: 6000 epoch: 33 loss: 19.187590691312675 loss_input: 82.19592075637134
step: 7000 epoch: 33 loss: 19.13875388663218 loss_input: 82.06096236914537
step: 8000 epoch: 33 loss: 19.156047679263196 loss_input: 82.08945511907447
step: 9000 epoch: 33 loss: 19.146782806351137 loss_input: 82.10899211475417
step: 10000 epoch: 33 loss: 19.14927994099966 loss_input: 82.18272684450305
step: 11000 epoch: 33 loss: 19.139658866454422 loss_input: 82.1938585750017
step: 12000 epoch: 33 loss: 19.110679491809304 loss_input: 82.03856869552862
step: 13000 epoch: 33 loss: 19.12757242937178 loss_input: 82.0849630313143
step: 14000 epoch: 33 loss: 19.127565977871566 loss_input: 82.07667292912393
step: 15000 epoch: 33 loss: 19.143840535276215 loss_input: 82.12521516306465
Save loss: 19.1608618029058 Name: 33_train_model.pth
step: 0 epoch: 34 loss: 30.804092407226562 loss_input: 107.24560546875
step: 1000 epoch: 34 loss: 18.881446089539732 loss_input: 81.64388083839988
step: 2000 epoch: 34 loss: 18.947149874864966 loss_input: 81.81163681464932
step: 3000 epoch: 34 loss: 18.989414794410877 loss_input: 82.03671149737197
step: 4000 epoch: 34 loss: 19.038558166106323 loss_input: 82.18365380883783
step: 5000 epoch: 34 loss: 19.00490991117191 loss_input: 81.95964613229698
step: 6000 epoch: 34 loss: 19.03156899114665 loss_input: 82.16362936499516
step: 7000 epoch: 34 loss: 19.063426913916768 loss_input: 82.2045243710999
step: 8000 epoch: 34 loss: 19.04118618069999 loss_input: 82.10328291177959
step: 9000 epoch: 34 loss: 19.064465191957353 loss_input: 82.14389054021125
step: 10000 epoch: 34 loss: 19.054875152395457 loss_input: 82.15016226038529
step: 11000 epoch: 34 loss: 19.05100893822597 loss_input: 82.1454239245296
step: 12000 epoch: 34 loss: 19.06687390469539 loss_input: 82.27966239426337
step: 13000 epoch: 34 loss: 19.091791685558576 loss_input: 82.40039379388935
step: 14000 epoch: 34 loss: 19.102043026711684 loss_input: 82.31370603393702
step: 15000 epoch: 34 loss: 19.111136542344983 loss_input: 82.24053118138478
Save loss: 19.117054642409087 Name: 34_train_model.pth
step: 0 epoch: 35 loss: 12.800299644470215 loss_input: 110.2969970703125
step: 1000 epoch: 35 loss: 18.85174791200773 loss_input: 80.55627002392139
step: 2000 epoch: 35 loss: 18.839032837773846 loss_input: 80.64376161528611
step: 3000 epoch: 35 loss: 18.915475370247577 loss_input: 81.09864308332769
step: 4000 epoch: 35 loss: 18.88569120632592 loss_input: 81.28265962073935
step: 5000 epoch: 35 loss: 18.928430237547918 loss_input: 81.87855195074266
step: 6000 epoch: 35 loss: 18.973762161154447 loss_input: 82.15824022819113
step: 7000 epoch: 35 loss: 18.97146481572688 loss_input: 82.19805236040499
step: 8000 epoch: 35 loss: 19.010009005820358 loss_input: 82.131175375539
step: 9000 epoch: 35 loss: 19.036175044797922 loss_input: 82.14224816491743
step: 10000 epoch: 35 loss: 19.03153584904819 loss_input: 82.08635320549976
step: 11000 epoch: 35 loss: 19.03462649646558 loss_input: 82.16462243555806
step: 12000 epoch: 35 loss: 19.036642625266122 loss_input: 82.18592213364543
step: 13000 epoch: 35 loss: 19.044848532816435 loss_input: 82.19819263545983
step: 14000 epoch: 35 loss: 19.06322031247259 loss_input: 82.1042626681102
step: 15000 epoch: 35 loss: 19.0775778255942 loss_input: 82.15486056626173
Save loss: 19.089863594204186 Name: 35_train_model.pth
step: 0 epoch: 36 loss: 22.351980209350586 loss_input: 86.256591796875
step: 1000 epoch: 36 loss: 18.888568071694998 loss_input: 83.16567801095388
step: 2000 epoch: 36 loss: 18.974333957813194 loss_input: 82.37126117727269
step: 3000 epoch: 36 loss: 19.102829287267454 loss_input: 82.7456915403199
step: 4000 epoch: 36 loss: 19.041161043886483 loss_input: 82.64667879966044
step: 5000 epoch: 36 loss: 19.041258442857174 loss_input: 82.42299953095318
step: 6000 epoch: 36 loss: 19.011607332520438 loss_input: 82.207423294848
step: 7000 epoch: 36 loss: 19.012626173564016 loss_input: 82.20823131747083
step: 8000 epoch: 36 loss: 18.994704948993135 loss_input: 82.15621033210692
step: 9000 epoch: 36 loss: 19.01000318526162 loss_input: 82.02391783399935
step: 10000 epoch: 36 loss: 19.02034988227862 loss_input: 82.05135256737998
step: 11000 epoch: 36 loss: 19.042007254574603 loss_input: 82.07753105985394
step: 12000 epoch: 36 loss: 19.06351837127688 loss_input: 82.19766888119024
step: 13000 epoch: 36 loss: 19.050347727359732 loss_input: 82.17763795625997
step: 14000 epoch: 36 loss: 19.043582639015792 loss_input: 82.1563389436678
step: 15000 epoch: 36 loss: 19.0495995977276 loss_input: 82.170247894932
Save loss: 19.06666058830917 Name: 36_train_model.pth
step: 0 epoch: 37 loss: 15.023008346557617 loss_input: 93.5755615234375
step: 1000 epoch: 37 loss: 19.15406918216061 loss_input: 83.79923171311111
step: 2000 epoch: 37 loss: 19.107093949010526 loss_input: 82.7485756633402
step: 3000 epoch: 37 loss: 19.066086538550618 loss_input: 82.30828540144822
step: 4000 epoch: 37 loss: 19.028867054033267 loss_input: 82.34808630300921
step: 5000 epoch: 37 loss: 18.990350076232616 loss_input: 82.20203635054239
step: 6000 epoch: 37 loss: 18.997017434032294 loss_input: 82.01618389732896
step: 7000 epoch: 37 loss: 19.01209019681519 loss_input: 82.1399389146277
step: 8000 epoch: 37 loss: 19.037495253786656 loss_input: 82.38781478151412
step: 9000 epoch: 37 loss: 19.014349850558293 loss_input: 82.2981036842803
step: 10000 epoch: 37 loss: 19.01605107590933 loss_input: 82.36638075084093
step: 11000 epoch: 37 loss: 19.012872588991 loss_input: 82.30749565535768
step: 12000 epoch: 37 loss: 19.010187705351246 loss_input: 82.24536608847049
step: 13000 epoch: 37 loss: 19.01366209134754 loss_input: 82.29977103154775
step: 14000 epoch: 37 loss: 19.030488198369362 loss_input: 82.26135209005021
step: 15000 epoch: 37 loss: 19.02870848121488 loss_input: 82.24861495236254
Save loss: 19.016606358468533 Name: 37_train_model.pth
step: 0 epoch: 38 loss: 19.811065673828125 loss_input: 99.68621826171875
step: 1000 epoch: 38 loss: 18.496894881203698 loss_input: 81.38111497877122
step: 2000 epoch: 38 loss: 18.92650258475575 loss_input: 82.3759649106111
step: 3000 epoch: 38 loss: 18.887824012771603 loss_input: 82.308376089806
step: 4000 epoch: 38 loss: 18.854558047757273 loss_input: 82.36064663948758
step: 5000 epoch: 38 loss: 18.877422920061907 loss_input: 82.11998427951129
step: 6000 epoch: 38 loss: 18.880525504325036 loss_input: 82.13413965104124
step: 7000 epoch: 38 loss: 18.908199939740044 loss_input: 82.31361423814455
step: 8000 epoch: 38 loss: 18.935987016287854 loss_input: 82.46426079979749
step: 9000 epoch: 38 loss: 18.95348188819097 loss_input: 82.40210300662123
step: 10000 epoch: 38 loss: 18.96172400432019 loss_input: 82.43554151054622
step: 11000 epoch: 38 loss: 18.96331948259182 loss_input: 82.44184708350377
step: 12000 epoch: 38 loss: 18.982811201454133 loss_input: 82.43056998464647
step: 13000 epoch: 38 loss: 19.04001427945628 loss_input: 82.29194210496428
step: 14000 epoch: 38 loss: 19.03146424760785 loss_input: 82.17116932705142
step: 15000 epoch: 38 loss: 19.017370997329653 loss_input: 82.16552372664088
Save loss: 19.045637465551497 Name: 38_train_model.pth
step: 0 epoch: 39 loss: 9.168071746826172 loss_input: 67.392822265625
step: 1000 epoch: 39 loss: 18.882423362293682 loss_input: 81.46068104259022
step: 2000 epoch: 39 loss: 18.76843031640651 loss_input: 81.78783493385143
step: 3000 epoch: 39 loss: 18.83537929402078 loss_input: 82.03213674868793
step: 4000 epoch: 39 loss: 18.893330635651445 loss_input: 82.27013235704746
step: 5000 epoch: 39 loss: 18.866489758469587 loss_input: 82.09906755221222
step: 6000 epoch: 39 loss: 18.883134227179625 loss_input: 82.09823827579844
step: 7000 epoch: 39 loss: 18.87797104629546 loss_input: 82.1233927118252
step: 8000 epoch: 39 loss: 18.86279744500593 loss_input: 82.07322614488862
step: 9000 epoch: 39 loss: 18.886465683736716 loss_input: 82.09549437405175
step: 10000 epoch: 39 loss: 18.90434280172275 loss_input: 82.03096482343953
step: 11000 epoch: 39 loss: 18.900724791427187 loss_input: 82.00666480493074
step: 12000 epoch: 39 loss: 18.94271102182846 loss_input: 82.16274848698318
step: 13000 epoch: 39 loss: 18.98448246241111 loss_input: 82.24871283470232
step: 14000 epoch: 39 loss: 18.994130115186852 loss_input: 82.3023191781293
step: 15000 epoch: 39 loss: 18.985428567346226 loss_input: 82.24458545211569
Save loss: 18.993170244261623 Name: 39_train_model.pth
step: 0 epoch: 40 loss: 20.29490852355957 loss_input: 103.9859619140625
step: 1000 epoch: 40 loss: 18.773845592102447 loss_input: 81.81074601667864
step: 2000 epoch: 40 loss: 18.779407179993072 loss_input: 81.8424519124715
step: 3000 epoch: 40 loss: 18.817313139456903 loss_input: 82.164007973091
step: 4000 epoch: 40 loss: 18.844813721324766 loss_input: 82.38555166811325
step: 5000 epoch: 40 loss: 18.85724297448936 loss_input: 82.06687363699135
step: 6000 epoch: 40 loss: 18.89850880435816 loss_input: 82.22651469709476
step: 7000 epoch: 40 loss: 18.913400354155165 loss_input: 82.19280660624096
step: 8000 epoch: 40 loss: 18.94860063477049 loss_input: 82.33004924372247
step: 9000 epoch: 40 loss: 18.912086754133405 loss_input: 82.2146558910989
step: 10000 epoch: 40 loss: 18.91937984059947 loss_input: 82.19505728870472
step: 11000 epoch: 40 loss: 18.925504495204443 loss_input: 82.21204059352203
step: 12000 epoch: 40 loss: 18.926936968258346 loss_input: 82.1278596402367
step: 13000 epoch: 40 loss: 18.9334945974694 loss_input: 82.1503940661791
step: 14000 epoch: 40 loss: 18.93565767143941 loss_input: 82.21060491267225
step: 15000 epoch: 40 loss: 18.931093336097337 loss_input: 82.21841746601659
Save loss: 18.939661923348904 Name: 40_train_model.pth
step: 0 epoch: 41 loss: 7.523734092712402 loss_input: 43.97589111328125
step: 1000 epoch: 41 loss: 18.5768765774402 loss_input: 82.38885132201783
step: 2000 epoch: 41 loss: 18.651453181661886 loss_input: 82.07338438934829
step: 3000 epoch: 41 loss: 18.883259749579373 loss_input: 82.22269568591068
step: 4000 epoch: 41 loss: 18.856778460781268 loss_input: 82.13534935663057
step: 5000 epoch: 41 loss: 18.910304703681 loss_input: 82.1546170258136
step: 6000 epoch: 41 loss: 18.916922551952705 loss_input: 82.09348672804207
step: 7000 epoch: 41 loss: 18.914860226566187 loss_input: 82.14196224618581
step: 8000 epoch: 41 loss: 18.908354039162997 loss_input: 82.01448039820218
step: 9000 epoch: 41 loss: 18.902045209147428 loss_input: 82.04122695270188
step: 10000 epoch: 41 loss: 18.936803374191772 loss_input: 82.09811390687103
step: 11000 epoch: 41 loss: 18.934482398439282 loss_input: 82.18509431826332
step: 12000 epoch: 41 loss: 18.915903751775232 loss_input: 82.15128630739919
step: 13000 epoch: 41 loss: 18.89876584815627 loss_input: 82.08888661866004
step: 14000 epoch: 41 loss: 18.914730757102397 loss_input: 82.17960245794386
step: 15000 epoch: 41 loss: 18.920408694221692 loss_input: 82.20727029656356
Save loss: 18.916180273279547 Name: 41_train_model.pth
step: 0 epoch: 42 loss: 17.570083618164062 loss_input: 106.180419921875
step: 1000 epoch: 42 loss: 18.745886931290755 loss_input: 81.9952195021775
step: 2000 epoch: 42 loss: 18.886663276275833 loss_input: 82.45976099474677
step: 3000 epoch: 42 loss: 18.830690153357747 loss_input: 82.13659236797369
step: 4000 epoch: 42 loss: 18.842352435815872 loss_input: 82.38594520071155
step: 5000 epoch: 42 loss: 18.84319369045884 loss_input: 82.42984531755758
step: 6000 epoch: 42 loss: 18.84752311994187 loss_input: 82.31161557505715
step: 7000 epoch: 42 loss: 18.856173956944183 loss_input: 82.3406909713233
step: 8000 epoch: 42 loss: 18.896543912359544 loss_input: 82.5720435992254
step: 9000 epoch: 42 loss: 18.895285438158925 loss_input: 82.60723674881393
step: 10000 epoch: 42 loss: 18.890806081282854 loss_input: 82.49165732230487
step: 11000 epoch: 42 loss: 18.897199422616804 loss_input: 82.44257505576553
step: 12000 epoch: 42 loss: 18.904782391440797 loss_input: 82.41224160173338
step: 13000 epoch: 42 loss: 18.914809769790416 loss_input: 82.42257333870953
step: 14000 epoch: 42 loss: 18.888729644651015 loss_input: 82.31862250928087
step: 15000 epoch: 42 loss: 18.889454772683607 loss_input: 82.20950451040895
Save loss: 18.911095961168407 Name: 42_train_model.pth
step: 0 epoch: 43 loss: 20.43075180053711 loss_input: 87.548095703125
step: 1000 epoch: 43 loss: 18.666382752455675 loss_input: 82.18381124490743
step: 2000 epoch: 43 loss: 18.712144511631283 loss_input: 82.62057173317638
step: 3000 epoch: 43 loss: 18.81459611648323 loss_input: 82.940700755998
step: 4000 epoch: 43 loss: 18.786555492886897 loss_input: 82.81680399297149
step: 5000 epoch: 43 loss: 18.85209403083792 loss_input: 82.79946358140481
step: 6000 epoch: 43 loss: 18.845375624205186 loss_input: 82.69540034546651
step: 7000 epoch: 43 loss: 18.84706032965766 loss_input: 82.63293733393834
step: 8000 epoch: 43 loss: 18.85772318342986 loss_input: 82.55463533672061
step: 9000 epoch: 43 loss: 18.855260304379048 loss_input: 82.58726639965352
step: 10000 epoch: 43 loss: 18.853785470418604 loss_input: 82.47814214550225
step: 11000 epoch: 43 loss: 18.84223175614479 loss_input: 82.397048976549
step: 12000 epoch: 43 loss: 18.855589235060393 loss_input: 82.34142419996087
step: 13000 epoch: 43 loss: 18.86416796353879 loss_input: 82.23697858296508
step: 14000 epoch: 43 loss: 18.86664317086904 loss_input: 82.19457786793828
step: 15000 epoch: 43 loss: 18.880926175162312 loss_input: 82.25067845818742
Save loss: 18.86645991243422 Name: 43_train_model.pth
step: 0 epoch: 44 loss: 19.595348358154297 loss_input: 97.21673583984375
step: 1000 epoch: 44 loss: 19.07145075174002 loss_input: 82.67066746729833
step: 2000 epoch: 44 loss: 18.853896161545997 loss_input: 82.34885209372852
step: 3000 epoch: 44 loss: 18.83417438896685 loss_input: 82.3220351720325
step: 4000 epoch: 44 loss: 18.800919245195757 loss_input: 81.90220885025326
step: 5000 epoch: 44 loss: 18.8320428946094 loss_input: 82.02824065313891
step: 6000 epoch: 44 loss: 18.823823628237278 loss_input: 81.99673134921849
step: 7000 epoch: 44 loss: 18.80438759394704 loss_input: 81.80395415401037
step: 8000 epoch: 44 loss: 18.8295854093015 loss_input: 82.00249961125465
step: 9000 epoch: 44 loss: 18.837261555870565 loss_input: 81.89583120186082
step: 10000 epoch: 44 loss: 18.841118061832162 loss_input: 81.90123528540701
step: 11000 epoch: 44 loss: 18.83246095832202 loss_input: 81.9613772571634
step: 12000 epoch: 44 loss: 18.815472648636657 loss_input: 81.86120604960166
step: 13000 epoch: 44 loss: 18.842876844649663 loss_input: 81.88242997515064
step: 14000 epoch: 44 loss: 18.833967741570568 loss_input: 82.01243250952918
step: 15000 epoch: 44 loss: 18.82495426308369 loss_input: 82.13964712736599
Save loss: 18.839103874638678 Name: 44_train_model.pth
step: 0 epoch: 45 loss: 13.002021789550781 loss_input: 59.87847900390625
step: 1000 epoch: 45 loss: 18.70951870319012 loss_input: 81.78156474872783
step: 2000 epoch: 45 loss: 18.874816871177906 loss_input: 81.80474414282116
step: 3000 epoch: 45 loss: 18.906571910048438 loss_input: 82.13079415015959
step: 4000 epoch: 45 loss: 18.853097262128657 loss_input: 81.62241923955047
step: 5000 epoch: 45 loss: 18.81828304425022 loss_input: 82.04902109177773
step: 6000 epoch: 45 loss: 18.819235991923097 loss_input: 82.33381057584153
step: 7000 epoch: 45 loss: 18.783204790558614 loss_input: 82.17976953696905
step: 8000 epoch: 45 loss: 18.792101682208358 loss_input: 82.0638568860533
step: 9000 epoch: 45 loss: 18.78671419121215 loss_input: 82.03633149376631
step: 10000 epoch: 45 loss: 18.790845385838384 loss_input: 82.0807740515011
step: 11000 epoch: 45 loss: 18.79464870968165 loss_input: 82.1639763428378
step: 12000 epoch: 45 loss: 18.7931249101364 loss_input: 82.1075702696162
step: 13000 epoch: 45 loss: 18.801291360313016 loss_input: 82.18593241850988
step: 14000 epoch: 45 loss: 18.815865421642552 loss_input: 82.16156249982562
step: 15000 epoch: 45 loss: 18.82045877117307 loss_input: 82.13610448024168
Save loss: 18.828858934313057 Name: 45_train_model.pth
step: 0 epoch: 46 loss: 24.81743621826172 loss_input: 83.4210205078125
step: 1000 epoch: 46 loss: 18.66554189752508 loss_input: 83.08984009154908
step: 2000 epoch: 46 loss: 18.798815359418718 loss_input: 82.49309210751069
step: 3000 epoch: 46 loss: 18.727609312721032 loss_input: 82.3086730489251
step: 4000 epoch: 46 loss: 18.780579899525947 loss_input: 82.52108567096506
step: 5000 epoch: 46 loss: 18.805509020866953 loss_input: 82.5105923395399
step: 6000 epoch: 46 loss: 18.761351657815624 loss_input: 82.25153667015783
step: 7000 epoch: 46 loss: 18.798250668560705 loss_input: 82.34349556334307
step: 8000 epoch: 46 loss: 18.797918890077103 loss_input: 82.24389878816417
step: 9000 epoch: 46 loss: 18.759583567555858 loss_input: 82.16046654538384
step: 10000 epoch: 46 loss: 18.763440402719144 loss_input: 82.11115499778147
step: 11000 epoch: 46 loss: 18.767325600345895 loss_input: 82.17556628707582
step: 12000 epoch: 46 loss: 18.765411569221687 loss_input: 82.24180635195276
step: 13000 epoch: 46 loss: 18.761148303080116 loss_input: 82.32614861769947
step: 14000 epoch: 46 loss: 18.76023378001648 loss_input: 82.30654142815831
step: 15000 epoch: 46 loss: 18.77188778023713 loss_input: 82.2871585009567
Save loss: 18.773159926995636 Name: 46_train_model.pth
step: 0 epoch: 47 loss: 17.866779327392578 loss_input: 67.50933837890625
step: 1000 epoch: 47 loss: 19.047497401585233 loss_input: 82.53924572741711
step: 2000 epoch: 47 loss: 18.90376475285078 loss_input: 82.21463108777643
step: 3000 epoch: 47 loss: 18.96436812805359 loss_input: 82.37951471010314
step: 4000 epoch: 47 loss: 18.895470773181568 loss_input: 82.3776746700776
step: 5000 epoch: 47 loss: 18.79993344707218 loss_input: 82.05571654223843
step: 6000 epoch: 47 loss: 18.80104733268294 loss_input: 82.01343983766378
step: 7000 epoch: 47 loss: 18.78001296610479 loss_input: 82.10625721158138
step: 8000 epoch: 47 loss: 18.77735293494092 loss_input: 82.31069488964026
step: 9000 epoch: 47 loss: 18.780285194680076 loss_input: 82.21981524351027
step: 10000 epoch: 47 loss: 18.74415965533688 loss_input: 82.11563474389865
step: 11000 epoch: 47 loss: 18.7570453409433 loss_input: 82.15442316190361
step: 12000 epoch: 47 loss: 18.751895456927567 loss_input: 82.10961932880105
step: 13000 epoch: 47 loss: 18.73350190369957 loss_input: 82.18150629225937
step: 14000 epoch: 47 loss: 18.741380089666578 loss_input: 82.21312046698115
step: 15000 epoch: 47 loss: 18.745860457905103 loss_input: 82.20275064751543
Save loss: 18.764911718308927 Name: 47_train_model.pth
step: 0 epoch: 48 loss: 24.735694885253906 loss_input: 75.040771484375
step: 1000 epoch: 48 loss: 18.791491088810023 loss_input: 82.93543017041553
step: 2000 epoch: 48 loss: 18.623808702547986 loss_input: 81.92536449670672
step: 3000 epoch: 48 loss: 18.546824320679068 loss_input: 81.72599329276309
step: 4000 epoch: 48 loss: 18.691289796021188 loss_input: 81.93018009840802
step: 5000 epoch: 48 loss: 18.709019502003986 loss_input: 81.96834956739121
step: 6000 epoch: 48 loss: 18.656656298671557 loss_input: 81.84580604363791
step: 7000 epoch: 48 loss: 18.6807251998551 loss_input: 82.00045036639575
step: 8000 epoch: 48 loss: 18.666604316826092 loss_input: 82.02543922579746
step: 9000 epoch: 48 loss: 18.65613561330299 loss_input: 82.01646906989718
step: 10000 epoch: 48 loss: 18.685411669113506 loss_input: 82.11956943954043
step: 11000 epoch: 48 loss: 18.67978859647774 loss_input: 82.13185401890844
step: 12000 epoch: 48 loss: 18.689805331940196 loss_input: 82.11974775214044
step: 13000 epoch: 48 loss: 18.697949991108096 loss_input: 82.20111255339133
step: 14000 epoch: 48 loss: 18.710186278902626 loss_input: 82.22629298800086
step: 15000 epoch: 48 loss: 18.723981133699972 loss_input: 82.20881885869068
Save loss: 18.713147618725895 Name: 48_train_model.pth
step: 0 epoch: 49 loss: 15.903165817260742 loss_input: 63.1826171875
step: 1000 epoch: 49 loss: 18.456301559577813 loss_input: 81.97857842840753
step: 2000 epoch: 49 loss: 18.412013545505765 loss_input: 81.70839381944769
step: 3000 epoch: 49 loss: 18.527292065841284 loss_input: 82.0077186185334
step: 4000 epoch: 49 loss: 18.59381073506228 loss_input: 82.17445601978412
step: 5000 epoch: 49 loss: 18.646194188457994 loss_input: 82.21418893711493
step: 6000 epoch: 49 loss: 18.659806645883954 loss_input: 82.29858568290376
step: 7000 epoch: 49 loss: 18.673829926097245 loss_input: 82.40949282287241
step: 8000 epoch: 49 loss: 18.665320549528534 loss_input: 82.40288076173096
step: 9000 epoch: 49 loss: 18.70294407613674 loss_input: 82.49630199915939
step: 10000 epoch: 49 loss: 18.717061197837584 loss_input: 82.50264228948198
step: 11000 epoch: 49 loss: 18.712992043681993 loss_input: 82.30945324106722
step: 12000 epoch: 49 loss: 18.726327704485332 loss_input: 82.27207367118821
step: 13000 epoch: 49 loss: 18.724886382509126 loss_input: 82.17062098363228
step: 14000 epoch: 49 loss: 18.727040273054577 loss_input: 82.07822346447213
step: 15000 epoch: 49 loss: 18.71591639234244 loss_input: 82.07292279147536
Save loss: 18.73063112848997 Name: 49_train_model.pth
step: 0 epoch: 50 loss: 18.815370559692383 loss_input: 109.45831298828125
step: 1000 epoch: 50 loss: 18.729242356268916 loss_input: 82.46716881751061
step: 2000 epoch: 50 loss: 18.738796282743944 loss_input: 82.69266605710817
step: 3000 epoch: 50 loss: 18.687741230027513 loss_input: 82.55487058513047
step: 4000 epoch: 50 loss: 18.662703966742843 loss_input: 82.72038730124598
step: 5000 epoch: 50 loss: 18.656020611578214 loss_input: 82.54626084060531
step: 6000 epoch: 50 loss: 18.672522973068713 loss_input: 82.50935573034377
step: 7000 epoch: 50 loss: 18.66193451593304 loss_input: 82.46633665719351
step: 8000 epoch: 50 loss: 18.687873132436547 loss_input: 82.59357900086708
step: 9000 epoch: 50 loss: 18.70821435275892 loss_input: 82.50959383012348
step: 10000 epoch: 50 loss: 18.72946019869258 loss_input: 82.60966394815597
step: 11000 epoch: 50 loss: 18.721808943788783 loss_input: 82.46666633821641
step: 12000 epoch: 50 loss: 18.728688295598168 loss_input: 82.4259242078541
step: 13000 epoch: 50 loss: 18.72018739280586 loss_input: 82.3097941393706
step: 14000 epoch: 50 loss: 18.697013442307384 loss_input: 82.2306139379065
step: 15000 epoch: 50 loss: 18.705031053947295 loss_input: 82.23343503174007
Save loss: 18.704666102319955 Name: 50_train_model.pth
step: 0 epoch: 51 loss: 14.566652297973633 loss_input: 64.09783935546875
step: 1000 epoch: 51 loss: 18.37982929384077 loss_input: 81.19156850229848
step: 2000 epoch: 51 loss: 18.348517188663664 loss_input: 81.11554189946042
step: 3000 epoch: 51 loss: 18.419456640031886 loss_input: 81.13346940586861
step: 4000 epoch: 51 loss: 18.46985476245227 loss_input: 81.51043026901966
step: 5000 epoch: 51 loss: 18.4916051208818 loss_input: 81.80525926064787
step: 6000 epoch: 51 loss: 18.539729563638858 loss_input: 81.68634456309691
step: 7000 epoch: 51 loss: 18.550701531831272 loss_input: 81.80106360189336
step: 8000 epoch: 51 loss: 18.557778735948105 loss_input: 81.7656773692473
step: 9000 epoch: 51 loss: 18.626121790538086 loss_input: 81.99977917221437
step: 10000 epoch: 51 loss: 18.646031045660997 loss_input: 82.11601180580185
step: 11000 epoch: 51 loss: 18.63623908393741 loss_input: 82.17270584044029
step: 12000 epoch: 51 loss: 18.637993007289918 loss_input: 82.13988851453948
step: 13000 epoch: 51 loss: 18.631591881672133 loss_input: 82.12428733321596
step: 14000 epoch: 51 loss: 18.63944337804116 loss_input: 82.13716324601256
step: 15000 epoch: 51 loss: 18.666877749633585 loss_input: 82.27385412261579
Save loss: 18.66461094737053 Name: 51_train_model.pth
step: 0 epoch: 52 loss: 24.055702209472656 loss_input: 139.40972900390625
step: 1000 epoch: 52 loss: 18.873964678872 loss_input: 81.91685280051979
step: 2000 epoch: 52 loss: 18.87472551480226 loss_input: 81.90109608281797
step: 3000 epoch: 52 loss: 18.817310795788764 loss_input: 81.87588554872985
step: 4000 epoch: 52 loss: 18.749545134415897 loss_input: 82.0569115228517
step: 5000 epoch: 52 loss: 18.74312616305169 loss_input: 82.34418527671419
step: 6000 epoch: 52 loss: 18.705432240833066 loss_input: 82.28416730959879
step: 7000 epoch: 52 loss: 18.684711356790316 loss_input: 82.2708912939195
step: 8000 epoch: 52 loss: 18.716596346470048 loss_input: 82.34747962870608
step: 9000 epoch: 52 loss: 18.702012819709307 loss_input: 82.31471853062334
step: 10000 epoch: 52 loss: 18.67597678057874 loss_input: 82.26034552306488
step: 11000 epoch: 52 loss: 18.677409683896265 loss_input: 82.24939086902967
step: 12000 epoch: 52 loss: 18.693721815681727 loss_input: 82.26090808757473
step: 13000 epoch: 52 loss: 18.66625996047135 loss_input: 82.2877231395737
step: 14000 epoch: 52 loss: 18.69038147022448 loss_input: 82.39499370650422
step: 15000 epoch: 52 loss: 18.685612649998976 loss_input: 82.31530437440239
Save loss: 18.673245688185094 Name: 52_train_model.pth
step: 0 epoch: 53 loss: 17.491384506225586 loss_input: 83.7685546875
step: 1000 epoch: 53 loss: 18.273195739273543 loss_input: 82.72930335045814
step: 2000 epoch: 53 loss: 18.444904144616917 loss_input: 82.75921755918915
step: 3000 epoch: 53 loss: 18.57025935593465 loss_input: 82.89170974177227
step: 4000 epoch: 53 loss: 18.655032955327947 loss_input: 82.86033507187167
step: 5000 epoch: 53 loss: 18.627277447781164 loss_input: 82.81981301493607
step: 6000 epoch: 53 loss: 18.56712558141968 loss_input: 82.79049577349087
step: 7000 epoch: 53 loss: 18.595508351460165 loss_input: 82.64730439596799
step: 8000 epoch: 53 loss: 18.59029754214459 loss_input: 82.48147433108947
step: 9000 epoch: 53 loss: 18.587271445169144 loss_input: 82.384786239029
step: 10000 epoch: 53 loss: 18.575861547961377 loss_input: 82.3517323987816
step: 11000 epoch: 53 loss: 18.596322709392954 loss_input: 82.37674104156369
step: 12000 epoch: 53 loss: 18.617253015959385 loss_input: 82.40776494435197
step: 13000 epoch: 53 loss: 18.605588099340522 loss_input: 82.31441738462276
step: 14000 epoch: 53 loss: 18.606283654809705 loss_input: 82.30747876529327
step: 15000 epoch: 53 loss: 18.63130299705369 loss_input: 82.31264408626014
Save loss: 18.631678739503027 Name: 53_train_model.pth
step: 0 epoch: 54 loss: 19.417329788208008 loss_input: 68.1712646484375
step: 1000 epoch: 54 loss: 18.561607324636423 loss_input: 81.55867905288072
step: 2000 epoch: 54 loss: 18.50193032582124 loss_input: 81.63825301704617
step: 3000 epoch: 54 loss: 18.508423038738165 loss_input: 81.59075724351648
step: 4000 epoch: 54 loss: 18.570772378869545 loss_input: 81.60634392793403
step: 5000 epoch: 54 loss: 18.59292971737455 loss_input: 81.72483245050209
step: 6000 epoch: 54 loss: 18.619173222195208 loss_input: 81.93471254139935
step: 7000 epoch: 54 loss: 18.611172203335858 loss_input: 82.11446964398502
step: 8000 epoch: 54 loss: 18.601070750670022 loss_input: 82.04923703995009
step: 9000 epoch: 54 loss: 18.586366787418736 loss_input: 81.9806698452776
step: 10000 epoch: 54 loss: 18.56887313320975 loss_input: 81.91536910151758
step: 11000 epoch: 54 loss: 18.592007711057 loss_input: 82.0028166495695
step: 12000 epoch: 54 loss: 18.5799763059032 loss_input: 82.04694661878763
step: 13000 epoch: 54 loss: 18.595305326800833 loss_input: 82.12630686874748
step: 14000 epoch: 54 loss: 18.60185857364411 loss_input: 82.23854863899928
step: 15000 epoch: 54 loss: 18.648539719665205 loss_input: 82.29340574886153
Save loss: 18.64084163171053 Name: 54_train_model.pth
step: 0 epoch: 55 loss: 14.291421890258789 loss_input: 81.2415771484375
step: 1000 epoch: 55 loss: 18.62450559560831 loss_input: 83.8417421201845
step: 2000 epoch: 55 loss: 18.45454559345236 loss_input: 82.68209965451844
step: 3000 epoch: 55 loss: 18.50781759759737 loss_input: 82.68013457590959
step: 4000 epoch: 55 loss: 18.562016321819623 loss_input: 82.98516572639066
step: 5000 epoch: 55 loss: 18.545747710046612 loss_input: 82.78002320678442
step: 6000 epoch: 55 loss: 18.572672501541618 loss_input: 82.63747770757283
step: 7000 epoch: 55 loss: 18.581162382340263 loss_input: 82.77104975342529
step: 8000 epoch: 55 loss: 18.571858607267025 loss_input: 82.70401298104339
step: 9000 epoch: 55 loss: 18.584164510739008 loss_input: 82.76731623867964
step: 10000 epoch: 55 loss: 18.586382024133936 loss_input: 82.57935341719734
step: 11000 epoch: 55 loss: 18.579742764702775 loss_input: 82.55241232175804
step: 12000 epoch: 55 loss: 18.58537543601726 loss_input: 82.46285519195828
step: 13000 epoch: 55 loss: 18.59630285297098 loss_input: 82.36965876422967
step: 14000 epoch: 55 loss: 18.57232287706422 loss_input: 82.28370714783625
step: 15000 epoch: 55 loss: 18.580804800766323 loss_input: 82.3043668711474
Save loss: 18.590089395955204 Name: 55_train_model.pth
step: 0 epoch: 56 loss: 24.49609375 loss_input: 108.70465087890625
step: 1000 epoch: 56 loss: 18.44909172220068 loss_input: 81.27047372793223
step: 2000 epoch: 56 loss: 18.548760544711623 loss_input: 81.94733163203554
step: 3000 epoch: 56 loss: 18.54139954437617 loss_input: 82.02615219161972
step: 4000 epoch: 56 loss: 18.5856241427848 loss_input: 82.50821243968792
step: 5000 epoch: 56 loss: 18.55921552915903 loss_input: 82.60199428620135
step: 6000 epoch: 56 loss: 18.5513603868057 loss_input: 82.49277752007153
step: 7000 epoch: 56 loss: 18.548610730062908 loss_input: 82.41590052913757
step: 8000 epoch: 56 loss: 18.573433119063825 loss_input: 82.32516810185103
step: 9000 epoch: 56 loss: 18.576225723137977 loss_input: 82.43577501262881
step: 10000 epoch: 56 loss: 18.568331787460103 loss_input: 82.48617942771152
step: 11000 epoch: 56 loss: 18.56944720880106 loss_input: 82.47274362220622
step: 12000 epoch: 56 loss: 18.54495041663026 loss_input: 82.42648747980311
step: 13000 epoch: 56 loss: 18.550478956165904 loss_input: 82.39163426543811
step: 14000 epoch: 56 loss: 18.56057678557372 loss_input: 82.37605187886273
step: 15000 epoch: 56 loss: 18.566516759085516 loss_input: 82.25717490822878
Save loss: 18.578181147038936 Name: 56_train_model.pth
step: 0 epoch: 57 loss: 17.24602699279785 loss_input: 75.9659423828125
step: 1000 epoch: 57 loss: 18.6090881817348 loss_input: 83.10356117271401
step: 2000 epoch: 57 loss: 18.561822651267825 loss_input: 82.32444571781492
step: 3000 epoch: 57 loss: 18.442238745551155 loss_input: 82.10115728025553
step: 4000 epoch: 57 loss: 18.54578752751292 loss_input: 82.21665524780914
step: 5000 epoch: 57 loss: 18.488307272713318 loss_input: 82.08956198262301
step: 6000 epoch: 57 loss: 18.51167569198602 loss_input: 82.21665405619245
step: 7000 epoch: 57 loss: 18.51809123314682 loss_input: 82.1706912876146
step: 8000 epoch: 57 loss: 18.557698475720063 loss_input: 82.36996719709353
step: 9000 epoch: 57 loss: 18.57453804635403 loss_input: 82.31300380280013
step: 10000 epoch: 57 loss: 18.553628668548132 loss_input: 82.21721604084709
step: 11000 epoch: 57 loss: 18.559765104293476 loss_input: 82.2093632689997
step: 12000 epoch: 57 loss: 18.54948356965911 loss_input: 82.1895560318704
step: 13000 epoch: 57 loss: 18.532769123835433 loss_input: 82.0763689235819
step: 14000 epoch: 57 loss: 18.54512468246671 loss_input: 82.180487404499
step: 15000 epoch: 57 loss: 18.54988770781815 loss_input: 82.22909513551961
Save loss: 18.555805795922875 Name: 57_train_model.pth
step: 0 epoch: 58 loss: 22.87601661682129 loss_input: 114.20513916015625
step: 1000 epoch: 58 loss: 18.57880508411419 loss_input: 83.16972529423701
step: 2000 epoch: 58 loss: 18.538703294350825 loss_input: 82.58112206714026
step: 3000 epoch: 58 loss: 18.52249646290109 loss_input: 82.10585513650398
step: 4000 epoch: 58 loss: 18.516187009439562 loss_input: 82.30427688182935
step: 5000 epoch: 58 loss: 18.594390862609263 loss_input: 82.57309552493798
step: 6000 epoch: 58 loss: 18.592021991204984 loss_input: 82.42433230325871
step: 7000 epoch: 58 loss: 18.585114249432536 loss_input: 82.31763370090545
step: 8000 epoch: 58 loss: 18.577520025952012 loss_input: 82.24750497343838
step: 9000 epoch: 58 loss: 18.589034677862976 loss_input: 82.2972577496272
step: 10000 epoch: 58 loss: 18.5632966706877 loss_input: 82.26974668866121
step: 11000 epoch: 58 loss: 18.591155920209868 loss_input: 82.52479239613693
step: 12000 epoch: 58 loss: 18.58268033769784 loss_input: 82.35556173948395
step: 13000 epoch: 58 loss: 18.564410804629407 loss_input: 82.28349845609833
step: 14000 epoch: 58 loss: 18.547658317745196 loss_input: 82.23702963041703
step: 15000 epoch: 58 loss: 18.551958283379303 loss_input: 82.25144093583866
Save loss: 18.536083797872067 Name: 58_train_model.pth
step: 0 epoch: 59 loss: 18.356552124023438 loss_input: 61.050048828125
step: 1000 epoch: 59 loss: 18.369742842701886 loss_input: 82.26969783146541
step: 2000 epoch: 59 loss: 18.40354109287024 loss_input: 81.51267527247118
step: 3000 epoch: 59 loss: 18.53719402066631 loss_input: 81.72100899228252
step: 4000 epoch: 59 loss: 18.54509527306055 loss_input: 81.93954015463419
step: 5000 epoch: 59 loss: 18.49604917864541 loss_input: 81.64626303254974
step: 6000 epoch: 59 loss: 18.484484482161147 loss_input: 81.73267557620605
step: 7000 epoch: 59 loss: 18.5291781611416 loss_input: 82.00977466563091
step: 8000 epoch: 59 loss: 18.56787753519364 loss_input: 82.16777311863116
step: 9000 epoch: 59 loss: 18.541779677850144 loss_input: 82.08503633466724
step: 10000 epoch: 59 loss: 18.568163838723624 loss_input: 82.15355478612295
step: 11000 epoch: 59 loss: 18.554820368392026 loss_input: 82.257658000773
step: 12000 epoch: 59 loss: 18.54838153682404 loss_input: 82.20024899353277
step: 13000 epoch: 59 loss: 18.564813581542523 loss_input: 82.25733960781562
step: 14000 epoch: 59 loss: 18.553308648847185 loss_input: 82.24431470227015
step: 15000 epoch: 59 loss: 18.555885924457606 loss_input: 82.23080269176717
Save loss: 18.531541007757188 Name: 59_train_model.pth
step: 0 epoch: 60 loss: 26.145366668701172 loss_input: 115.041259765625
step: 1000 epoch: 60 loss: 18.53973324791892 loss_input: 82.08740874603912
step: 2000 epoch: 60 loss: 18.491278894658926 loss_input: 82.05035119769217
step: 3000 epoch: 60 loss: 18.517919652027434 loss_input: 82.66697569316088
step: 4000 epoch: 60 loss: 18.492003318280823 loss_input: 82.61416826579487
step: 5000 epoch: 60 loss: 18.50740646724819 loss_input: 82.72717507279793
step: 6000 epoch: 60 loss: 18.4697754290914 loss_input: 82.45725745945012
step: 7000 epoch: 60 loss: 18.471840276460686 loss_input: 82.37763042256519
step: 8000 epoch: 60 loss: 18.49887439868194 loss_input: 82.37724783456024
step: 9000 epoch: 60 loss: 18.466065801258765 loss_input: 82.18305185193182
step: 10000 epoch: 60 loss: 18.483322467676174 loss_input: 82.34606596713375
step: 11000 epoch: 60 loss: 18.490261941787903 loss_input: 82.35513970609384
step: 12000 epoch: 60 loss: 18.520774281508682 loss_input: 82.39971643089801
step: 13000 epoch: 60 loss: 18.526691429102094 loss_input: 82.41382403520792
step: 14000 epoch: 60 loss: 18.52261265280689 loss_input: 82.29438003486636
step: 15000 epoch: 60 loss: 18.5180235978691 loss_input: 82.27916130461094
Save loss: 18.50456010013819 Name: 60_train_model.pth
step: 0 epoch: 61 loss: 20.441734313964844 loss_input: 81.01409912109375
step: 1000 epoch: 61 loss: 18.30373631562148 loss_input: 81.93045388449441
step: 2000 epoch: 61 loss: 18.312971707524685 loss_input: 82.0468795143444
step: 3000 epoch: 61 loss: 18.446973950971724 loss_input: 82.22963227752207
step: 4000 epoch: 61 loss: 18.469793959934393 loss_input: 82.30982537568732
step: 5000 epoch: 61 loss: 18.417684937400644 loss_input: 82.1938067586678
step: 6000 epoch: 61 loss: 18.478294133782445 loss_input: 82.35085475256078
step: 7000 epoch: 61 loss: 18.451601580472833 loss_input: 82.46385412784223
step: 8000 epoch: 61 loss: 18.4527495144278 loss_input: 82.29053666570488
step: 9000 epoch: 61 loss: 18.439986169238896 loss_input: 82.17807359105282
step: 10000 epoch: 61 loss: 18.456321796075475 loss_input: 82.15092940779164
step: 11000 epoch: 61 loss: 18.454447810774056 loss_input: 82.15440546331726
step: 12000 epoch: 61 loss: 18.495764165885767 loss_input: 82.17794786835798
step: 13000 epoch: 61 loss: 18.491027813986186 loss_input: 82.21091036961249
step: 14000 epoch: 61 loss: 18.473683267122983 loss_input: 82.21247284303911
step: 15000 epoch: 61 loss: 18.478387538611624 loss_input: 82.17774237007247
Save loss: 18.493135017365216 Name: 61_train_model.pth
step: 0 epoch: 62 loss: 16.30118179321289 loss_input: 56.501708984375
step: 1000 epoch: 62 loss: 18.0614471264057 loss_input: 81.94238836115056
step: 2000 epoch: 62 loss: 18.295578054640664 loss_input: 81.89035218718766
step: 3000 epoch: 62 loss: 18.328059139111883 loss_input: 81.5779498874724
step: 4000 epoch: 62 loss: 18.365822846279894 loss_input: 81.70795104873685
step: 5000 epoch: 62 loss: 18.404236945026614 loss_input: 82.13733974396527
step: 6000 epoch: 62 loss: 18.42033274947276 loss_input: 82.01960345272857
step: 7000 epoch: 62 loss: 18.43070326864915 loss_input: 82.20864811932559
step: 8000 epoch: 62 loss: 18.39519820614407 loss_input: 82.15806764388826
step: 9000 epoch: 62 loss: 18.406149193361433 loss_input: 82.09940190564764
step: 10000 epoch: 62 loss: 18.412494074450816 loss_input: 82.15531791547407
step: 11000 epoch: 62 loss: 18.433339534895104 loss_input: 82.13286268853045
step: 12000 epoch: 62 loss: 18.479031900258555 loss_input: 82.27649235000274
step: 13000 epoch: 62 loss: 18.477217398297924 loss_input: 82.16071958463381
step: 14000 epoch: 62 loss: 18.4726561447968 loss_input: 82.20286790776802
step: 15000 epoch: 62 loss: 18.4791192128558 loss_input: 82.30778626802484
Save loss: 18.47531778559089 Name: 62_train_model.pth
step: 0 epoch: 63 loss: 19.5327205657959 loss_input: 77.81298828125
step: 1000 epoch: 63 loss: 18.36381157009037 loss_input: 81.85643439812141
step: 2000 epoch: 63 loss: 18.548118426405388 loss_input: 82.07100063249625
step: 3000 epoch: 63 loss: 18.510683270860856 loss_input: 81.88966267429086
step: 4000 epoch: 63 loss: 18.522673865074935 loss_input: 81.98380258756112
step: 5000 epoch: 63 loss: 18.46074933015068 loss_input: 81.94797498019928
step: 6000 epoch: 63 loss: 18.516263809269258 loss_input: 82.0175337293231
step: 7000 epoch: 63 loss: 18.489254661976073 loss_input: 81.87998928619851
step: 8000 epoch: 63 loss: 18.462579394113927 loss_input: 81.91295269152147
step: 9000 epoch: 63 loss: 18.448148587321906 loss_input: 81.97908990879269
step: 10000 epoch: 63 loss: 18.4701903759867 loss_input: 82.17437794184448
step: 11000 epoch: 63 loss: 18.460028929446416 loss_input: 82.18855916884864
step: 12000 epoch: 63 loss: 18.450285906672885 loss_input: 82.07366449524389
step: 13000 epoch: 63 loss: 18.455836739249253 loss_input: 82.06281887477256
step: 14000 epoch: 63 loss: 18.438810677675168 loss_input: 82.07055383756769
step: 15000 epoch: 63 loss: 18.457163143170675 loss_input: 82.23775413670339
Save loss: 18.46990330055356 Name: 63_train_model.pth
step: 0 epoch: 64 loss: 17.07563018798828 loss_input: 51.27178955078125
step: 1000 epoch: 64 loss: 18.325924870493886 loss_input: 82.21576708203905
step: 2000 epoch: 64 loss: 18.241080900360977 loss_input: 81.65365782074782
step: 3000 epoch: 64 loss: 18.276982269458713 loss_input: 81.81302289699006
step: 4000 epoch: 64 loss: 18.367697259063455 loss_input: 82.12807836248946
step: 5000 epoch: 64 loss: 18.359230170796284 loss_input: 82.00294923925371
step: 6000 epoch: 64 loss: 18.37573938031253 loss_input: 81.84539986133495
step: 7000 epoch: 64 loss: 18.416120624256173 loss_input: 81.95304541280655
step: 8000 epoch: 64 loss: 18.43879425017599 loss_input: 82.13013975364896
step: 9000 epoch: 64 loss: 18.4293886187765 loss_input: 82.30161294469885
step: 10000 epoch: 64 loss: 18.41103628761422 loss_input: 82.20285027161346
step: 11000 epoch: 64 loss: 18.401822778747555 loss_input: 82.13489719928693
step: 12000 epoch: 64 loss: 18.398509229464228 loss_input: 82.1568308231801
step: 13000 epoch: 64 loss: 18.428488511560918 loss_input: 82.19120748787053
step: 14000 epoch: 64 loss: 18.42857036303813 loss_input: 82.14371345039947
step: 15000 epoch: 64 loss: 18.44285054347029 loss_input: 82.14289649977111
Save loss: 18.449220652222632 Name: 64_train_model.pth
step: 0 epoch: 65 loss: 11.113054275512695 loss_input: 57.1435546875
step: 1000 epoch: 65 loss: 18.48809275522337 loss_input: 83.51129083319024
step: 2000 epoch: 65 loss: 18.32944726765245 loss_input: 82.91779799797366
step: 3000 epoch: 65 loss: 18.432591921883557 loss_input: 82.56389949687994
step: 4000 epoch: 65 loss: 18.432707659812667 loss_input: 82.4692239415732
step: 5000 epoch: 65 loss: 18.374872524436533 loss_input: 82.1619102937225
step: 6000 epoch: 65 loss: 18.44481715324064 loss_input: 82.27833649429196
step: 7000 epoch: 65 loss: 18.41633091274627 loss_input: 82.26063812870483
step: 8000 epoch: 65 loss: 18.432831612874114 loss_input: 82.18210856882635
step: 9000 epoch: 65 loss: 18.402440479259706 loss_input: 81.9942401283755
step: 10000 epoch: 65 loss: 18.408516825419547 loss_input: 82.08194737166909
step: 11000 epoch: 65 loss: 18.382983413699236 loss_input: 81.99362289419001
step: 12000 epoch: 65 loss: 18.352452638059663 loss_input: 81.96521580456674
step: 13000 epoch: 65 loss: 18.39646788542385 loss_input: 82.10814802951606
step: 14000 epoch: 65 loss: 18.40829228236074 loss_input: 82.07522380952281
step: 15000 epoch: 65 loss: 18.41209158470818 loss_input: 82.13896311941834
Save loss: 18.42771377392113 Name: 65_train_model.pth
step: 0 epoch: 66 loss: 21.094079971313477 loss_input: 107.89935302734375
step: 1000 epoch: 66 loss: 18.235237758952778 loss_input: 81.56860382049591
step: 2000 epoch: 66 loss: 18.235877974279994 loss_input: 81.94118898192505
step: 3000 epoch: 66 loss: 18.284729222463234 loss_input: 81.9681251472491
step: 4000 epoch: 66 loss: 18.272437734384592 loss_input: 81.91825824366663
step: 5000 epoch: 66 loss: 18.259577855709146 loss_input: 81.86064009122003
step: 6000 epoch: 66 loss: 18.281552966366885 loss_input: 81.9148815773543
step: 7000 epoch: 66 loss: 18.314855793819582 loss_input: 82.05575162672073
step: 8000 epoch: 66 loss: 18.329554025925127 loss_input: 82.00610823762996
step: 9000 epoch: 66 loss: 18.336712624547005 loss_input: 82.02493214593994
step: 10000 epoch: 66 loss: 18.35337318106778 loss_input: 82.06635094547185
step: 11000 epoch: 66 loss: 18.395148449253576 loss_input: 82.0878809545812
step: 12000 epoch: 66 loss: 18.394597585415227 loss_input: 82.05638652121601
step: 13000 epoch: 66 loss: 18.387982214994498 loss_input: 82.00429499995643
step: 14000 epoch: 66 loss: 18.38995765778058 loss_input: 82.0979107484231
step: 15000 epoch: 66 loss: 18.387760146253388 loss_input: 82.18454351578384
Save loss: 18.416565236106514 Name: 66_train_model.pth
step: 0 epoch: 67 loss: 17.920209884643555 loss_input: 57.5687255859375
step: 1000 epoch: 67 loss: 18.436850092389605 loss_input: 83.38947722199676
step: 2000 epoch: 67 loss: 18.383462094831682 loss_input: 82.48977985982594
step: 3000 epoch: 67 loss: 18.428518088489167 loss_input: 82.60423118644697
step: 4000 epoch: 67 loss: 18.360954439184184 loss_input: 82.28260168234308
step: 5000 epoch: 67 loss: 18.362992129309657 loss_input: 82.25149562372681
step: 6000 epoch: 67 loss: 18.387674401073014 loss_input: 82.45597116463662
step: 7000 epoch: 67 loss: 18.39711634071703 loss_input: 82.44772679307532
step: 8000 epoch: 67 loss: 18.412213826981088 loss_input: 82.53422005720965
step: 9000 epoch: 67 loss: 18.38492737983468 loss_input: 82.47965914079208
step: 10000 epoch: 67 loss: 18.38206222028497 loss_input: 82.48765655050705
step: 11000 epoch: 67 loss: 18.397140448293452 loss_input: 82.43049920488407
step: 12000 epoch: 67 loss: 18.396807369833418 loss_input: 82.3429085072175
step: 13000 epoch: 67 loss: 18.408953835822814 loss_input: 82.32130121695116
step: 14000 epoch: 67 loss: 18.412665764013962 loss_input: 82.26418496962829
step: 15000 epoch: 67 loss: 18.40955626251745 loss_input: 82.18147508427823
Save loss: 18.41004494212568 Name: 67_train_model.pth
step: 0 epoch: 68 loss: 23.085002899169922 loss_input: 75.00238037109375
step: 1000 epoch: 68 loss: 18.18786595989536 loss_input: 81.4830016175231
step: 2000 epoch: 68 loss: 18.29853755625887 loss_input: 82.64648108074869
step: 3000 epoch: 68 loss: 18.39223162836331 loss_input: 82.66479307109219
step: 4000 epoch: 68 loss: 18.384273394618265 loss_input: 82.50943061048703
step: 5000 epoch: 68 loss: 18.38414881806735 loss_input: 82.5123013239149
step: 6000 epoch: 68 loss: 18.37234293947695 loss_input: 82.3181076672768
step: 7000 epoch: 68 loss: 18.32894609015663 loss_input: 82.22805294869985
step: 8000 epoch: 68 loss: 18.35079263725991 loss_input: 82.30592386431432
step: 9000 epoch: 68 loss: 18.362500807534666 loss_input: 82.22825480328575
step: 10000 epoch: 68 loss: 18.353163314001545 loss_input: 82.12499636877132
step: 11000 epoch: 68 loss: 18.350078829829556 loss_input: 82.07659284614041
step: 12000 epoch: 68 loss: 18.367279156914613 loss_input: 82.11784630435257
step: 13000 epoch: 68 loss: 18.39061453804384 loss_input: 82.1812133742116
step: 14000 epoch: 68 loss: 18.392993484426505 loss_input: 82.22189546188247
step: 15000 epoch: 68 loss: 18.394055156308518 loss_input: 82.27414968803512
Save loss: 18.39136895343661 Name: 68_train_model.pth
step: 0 epoch: 69 loss: 21.194711685180664 loss_input: 108.695068359375
step: 1000 epoch: 69 loss: 18.050118747886483 loss_input: 81.68459958010739
step: 2000 epoch: 69 loss: 18.235465525865912 loss_input: 82.66464466741239
step: 3000 epoch: 69 loss: 18.275348622176853 loss_input: 82.29209455002629
step: 4000 epoch: 69 loss: 18.37544939917822 loss_input: 82.06682297016079
step: 5000 epoch: 69 loss: 18.366367589614555 loss_input: 82.13001327957065
step: 6000 epoch: 69 loss: 18.310513918726787 loss_input: 82.07236793338805
step: 7000 epoch: 69 loss: 18.287380822844682 loss_input: 82.01041509450938
step: 8000 epoch: 69 loss: 18.31899741768405 loss_input: 82.04299984352542
step: 9000 epoch: 69 loss: 18.310356820242866 loss_input: 82.0377275517564
step: 10000 epoch: 69 loss: 18.31515032676992 loss_input: 81.94943046588895
step: 11000 epoch: 69 loss: 18.33092300463412 loss_input: 81.96543774562753
step: 12000 epoch: 69 loss: 18.337211501051033 loss_input: 82.13360530604383
step: 13000 epoch: 69 loss: 18.35121142322325 loss_input: 82.13949926027325
step: 14000 epoch: 69 loss: 18.354363532945367 loss_input: 82.12892260189423
step: 15000 epoch: 69 loss: 18.362773943071357 loss_input: 82.16608540387672
Save loss: 18.38523136217892 Name: 69_train_model.pth
step: 0 epoch: 70 loss: 19.991531372070312 loss_input: 90.6571044921875
step: 1000 epoch: 70 loss: 18.585142339978898 loss_input: 84.00994842559784
step: 2000 epoch: 70 loss: 18.48132301175195 loss_input: 83.17774965666581
step: 3000 epoch: 70 loss: 18.412711701207222 loss_input: 82.745228702249
step: 4000 epoch: 70 loss: 18.332342258664077 loss_input: 82.69774035983191
step: 5000 epoch: 70 loss: 18.358166020528195 loss_input: 82.31322304874962
step: 6000 epoch: 70 loss: 18.35167726805321 loss_input: 82.34838314911381
step: 7000 epoch: 70 loss: 18.36822536335283 loss_input: 82.41435119864293
step: 8000 epoch: 70 loss: 18.35272664359891 loss_input: 82.38395233402221
step: 9000 epoch: 70 loss: 18.35091143467071 loss_input: 82.45658560724155
step: 10000 epoch: 70 loss: 18.357401271829985 loss_input: 82.34536640940398
step: 11000 epoch: 70 loss: 18.346892181325746 loss_input: 82.35624714381434
step: 12000 epoch: 70 loss: 18.341519071801326 loss_input: 82.27249486513331
step: 13000 epoch: 70 loss: 18.351986297689283 loss_input: 82.23843558195342
step: 14000 epoch: 70 loss: 18.358146408951015 loss_input: 82.24546222075098
step: 15000 epoch: 70 loss: 18.357521202713478 loss_input: 82.24598837779304
Save loss: 18.358933177769185 Name: 70_train_model.pth
step: 0 epoch: 71 loss: 12.611574172973633 loss_input: 78.81890869140625
step: 1000 epoch: 71 loss: 18.27520675401945 loss_input: 81.78118426983173
step: 2000 epoch: 71 loss: 18.398160007463463 loss_input: 82.48842525148558
step: 3000 epoch: 71 loss: 18.29107196630537 loss_input: 82.15532552381627
step: 4000 epoch: 71 loss: 18.270820268599042 loss_input: 82.2489242954154
step: 5000 epoch: 71 loss: 18.276209377284243 loss_input: 82.08864918910749
step: 6000 epoch: 71 loss: 18.31834815283891 loss_input: 82.22772311385603
step: 7000 epoch: 71 loss: 18.29482304064006 loss_input: 82.00360314911765
step: 8000 epoch: 71 loss: 18.267478298685013 loss_input: 82.00951038499338
step: 9000 epoch: 71 loss: 18.26620439237627 loss_input: 82.12029849602214
step: 10000 epoch: 71 loss: 18.263314371001254 loss_input: 82.03677734643527
step: 11000 epoch: 71 loss: 18.300164379149003 loss_input: 82.00526226131431
step: 12000 epoch: 71 loss: 18.319143919932447 loss_input: 81.95691473850975
step: 13000 epoch: 71 loss: 18.34242825628785 loss_input: 82.20664333569142
step: 14000 epoch: 71 loss: 18.332029711731025 loss_input: 82.28081852534389
step: 15000 epoch: 71 loss: 18.34328910934314 loss_input: 82.28438341333884
Save loss: 18.34811177405715 Name: 71_train_model.pth
step: 0 epoch: 72 loss: 28.839588165283203 loss_input: 77.16229248046875
step: 1000 epoch: 72 loss: 18.329670746009665 loss_input: 83.34788843968532
step: 2000 epoch: 72 loss: 18.350405121373868 loss_input: 82.8441547963811
step: 3000 epoch: 72 loss: 18.323593201298827 loss_input: 82.95237655156615
step: 4000 epoch: 72 loss: 18.383793103757483 loss_input: 82.80756684608144
step: 5000 epoch: 72 loss: 18.37658756939179 loss_input: 82.85330516904432
step: 6000 epoch: 72 loss: 18.385594244977472 loss_input: 82.7434538193016
step: 7000 epoch: 72 loss: 18.33421147630787 loss_input: 82.55211605512828
step: 8000 epoch: 72 loss: 18.337236277774906 loss_input: 82.30080878867193
step: 9000 epoch: 72 loss: 18.348007572238917 loss_input: 82.32477846157285
step: 10000 epoch: 72 loss: 18.36267777192999 loss_input: 82.38616361752497
step: 11000 epoch: 72 loss: 18.360396683925867 loss_input: 82.42102921285388
step: 12000 epoch: 72 loss: 18.375020771163292 loss_input: 82.50186846612065
step: 13000 epoch: 72 loss: 18.364716763735167 loss_input: 82.3688099009286
step: 14000 epoch: 72 loss: 18.355385875013944 loss_input: 82.3145741926637
step: 15000 epoch: 72 loss: 18.348260824906493 loss_input: 82.33981880049143
Save loss: 18.343533745080233 Name: 72_train_model.pth
step: 0 epoch: 73 loss: 20.291149139404297 loss_input: 59.90802001953125
step: 1000 epoch: 73 loss: 18.306307194830772 loss_input: 82.26188075840176
step: 2000 epoch: 73 loss: 18.264462534634248 loss_input: 81.86596655285638
step: 3000 epoch: 73 loss: 18.35490500263594 loss_input: 82.45025018515963
step: 4000 epoch: 73 loss: 18.350757791590198 loss_input: 82.64798137623796
step: 5000 epoch: 73 loss: 18.398548452026056 loss_input: 82.75414500840067
step: 6000 epoch: 73 loss: 18.388987685417934 loss_input: 82.78281801665868
step: 7000 epoch: 73 loss: 18.37596023513528 loss_input: 82.40293246333113
step: 8000 epoch: 73 loss: 18.36589185364052 loss_input: 82.288296345159
step: 9000 epoch: 73 loss: 18.339679743340117 loss_input: 82.11782137461071
step: 10000 epoch: 73 loss: 18.341554982818828 loss_input: 82.26257954648871
step: 11000 epoch: 73 loss: 18.296144003131673 loss_input: 82.12182105093606
step: 12000 epoch: 73 loss: 18.300799741694135 loss_input: 82.22249269958297
step: 13000 epoch: 73 loss: 18.30588529643788 loss_input: 82.14565367060857
step: 14000 epoch: 73 loss: 18.294261104114973 loss_input: 82.19611151519311
step: 15000 epoch: 73 loss: 18.305792797756915 loss_input: 82.23064175685813
Save loss: 18.31363930428028 Name: 73_train_model.pth
step: 0 epoch: 74 loss: 18.541805267333984 loss_input: 132.9453125
step: 1000 epoch: 74 loss: 18.512736273335886 loss_input: 83.07547012313859
step: 2000 epoch: 74 loss: 18.409226772965102 loss_input: 82.33031158981056
step: 3000 epoch: 74 loss: 18.278342723608095 loss_input: 82.22907222250787
step: 4000 epoch: 74 loss: 18.321344980625057 loss_input: 82.58537791699536
step: 5000 epoch: 74 loss: 18.327103089103936 loss_input: 82.4759318277946
step: 6000 epoch: 74 loss: 18.338327944626354 loss_input: 82.5435502367444
step: 7000 epoch: 74 loss: 18.326212575581735 loss_input: 82.38253550971513
step: 8000 epoch: 74 loss: 18.314305673285048 loss_input: 82.34195802581561
step: 9000 epoch: 74 loss: 18.304410940672923 loss_input: 82.26630474760617
step: 10000 epoch: 74 loss: 18.321770940014343 loss_input: 82.3930877908303
step: 11000 epoch: 74 loss: 18.312542492839903 loss_input: 82.38901576574537
step: 12000 epoch: 74 loss: 18.304316980502435 loss_input: 82.37232872907563
step: 13000 epoch: 74 loss: 18.301933349586342 loss_input: 82.29750594699597
step: 14000 epoch: 74 loss: 18.293242588868083 loss_input: 82.21553926568023
step: 15000 epoch: 74 loss: 18.304091009185534 loss_input: 82.17047670454782
Save loss: 18.30684738814831 Name: 74_train_model.pth
step: 0 epoch: 75 loss: 23.237693786621094 loss_input: 76.23065185546875
step: 1000 epoch: 75 loss: 18.29610526668918 loss_input: 82.64083469021213
step: 2000 epoch: 75 loss: 18.309481225449822 loss_input: 82.63981854897746
step: 3000 epoch: 75 loss: 18.282735174713594 loss_input: 82.205813678969
step: 4000 epoch: 75 loss: 18.24711916643928 loss_input: 81.83782295392949
step: 5000 epoch: 75 loss: 18.294543240743025 loss_input: 82.02792016059679
step: 6000 epoch: 75 loss: 18.270568745391724 loss_input: 82.11023224848267
step: 7000 epoch: 75 loss: 18.250443544647997 loss_input: 81.9965708198215
step: 8000 epoch: 75 loss: 18.245940298605614 loss_input: 81.9958360383785
step: 9000 epoch: 75 loss: 18.2647284550768 loss_input: 82.11557757145907
step: 10000 epoch: 75 loss: 18.266478848950815 loss_input: 82.16246164690172
step: 11000 epoch: 75 loss: 18.28330204081789 loss_input: 82.16855496157842
step: 12000 epoch: 75 loss: 18.2881311932044 loss_input: 82.18371748846776
step: 13000 epoch: 75 loss: 18.28630331085055 loss_input: 82.17369621469923
step: 14000 epoch: 75 loss: 18.2842846834594 loss_input: 82.17343472484248
step: 15000 epoch: 75 loss: 18.279210413943037 loss_input: 82.14023201269003
Save loss: 18.285625997185708 Name: 75_train_model.pth
step: 0 epoch: 76 loss: 12.062097549438477 loss_input: 64.91217041015625
step: 1000 epoch: 76 loss: 18.309223185528765 loss_input: 82.95349102801495
step: 2000 epoch: 76 loss: 18.287198496603597 loss_input: 82.68399021924584
step: 3000 epoch: 76 loss: 18.287562498765084 loss_input: 82.60537240760242
step: 4000 epoch: 76 loss: 18.31616914066724 loss_input: 82.52029854474858
step: 5000 epoch: 76 loss: 18.31062709839433 loss_input: 82.55055911425137
step: 6000 epoch: 76 loss: 18.28702662110706 loss_input: 82.74310167462323
step: 7000 epoch: 76 loss: 18.29209222621261 loss_input: 82.68034014288416
step: 8000 epoch: 76 loss: 18.275668787547996 loss_input: 82.39734884518829
step: 9000 epoch: 76 loss: 18.25919899197767 loss_input: 82.36065888783625
step: 10000 epoch: 76 loss: 18.239522913481853 loss_input: 82.29549637199366
step: 11000 epoch: 76 loss: 18.259085995014683 loss_input: 82.30205510991365
step: 12000 epoch: 76 loss: 18.252492021574653 loss_input: 82.2192517994106
step: 13000 epoch: 76 loss: 18.248172532704306 loss_input: 82.23638016051049
step: 14000 epoch: 76 loss: 18.263918250486277 loss_input: 82.27419135676274
step: 15000 epoch: 76 loss: 18.262747550422322 loss_input: 82.2243003908789
Save loss: 18.280666580066086 Name: 76_train_model.pth
step: 0 epoch: 77 loss: 13.30960750579834 loss_input: 48.17462158203125
step: 1000 epoch: 77 loss: 18.49633251441704 loss_input: 84.7674536766944
step: 2000 epoch: 77 loss: 18.1390281467066 loss_input: 82.98790424123875
step: 3000 epoch: 77 loss: 18.132863554148944 loss_input: 82.33319805670246
step: 4000 epoch: 77 loss: 18.131797775629906 loss_input: 82.04436392427772
step: 5000 epoch: 77 loss: 18.125768679615213 loss_input: 81.96527823341582
step: 6000 epoch: 77 loss: 18.168165682554445 loss_input: 81.96296745545665
step: 7000 epoch: 77 loss: 18.233042832289982 loss_input: 81.93410394845937
step: 8000 epoch: 77 loss: 18.238560163979233 loss_input: 81.9784756901115
step: 9000 epoch: 77 loss: 18.24108920326737 loss_input: 82.0713610827638
step: 10000 epoch: 77 loss: 18.25285289678773 loss_input: 82.14821957135341
step: 11000 epoch: 77 loss: 18.2757121891382 loss_input: 82.24886097668323
step: 12000 epoch: 77 loss: 18.264068537161318 loss_input: 82.15226513818347
step: 13000 epoch: 77 loss: 18.270569389063198 loss_input: 82.26985346736399
step: 14000 epoch: 77 loss: 18.292280012739955 loss_input: 82.2772380490191
step: 15000 epoch: 77 loss: 18.29270886252796 loss_input: 82.26103990121362
Save loss: 18.287646300166845 Name: 77_train_model.pth
step: 0 epoch: 78 loss: 12.794515609741211 loss_input: 54.24493408203125
step: 1000 epoch: 78 loss: 18.13454973447573 loss_input: 81.41968529517358
step: 2000 epoch: 78 loss: 18.134381474643156 loss_input: 81.66350323983517
step: 3000 epoch: 78 loss: 18.144422085751536 loss_input: 81.66225997990904
step: 4000 epoch: 78 loss: 18.218818812214174 loss_input: 82.13223288721277
step: 5000 epoch: 78 loss: 18.21354660199323 loss_input: 82.16660965902523
step: 6000 epoch: 78 loss: 18.18630217782777 loss_input: 82.09382339271579
step: 7000 epoch: 78 loss: 18.18110091780581 loss_input: 82.08873135136666
step: 8000 epoch: 78 loss: 18.200979880907582 loss_input: 82.10165108145661
step: 9000 epoch: 78 loss: 18.21879054551495 loss_input: 82.13915507733299
step: 10000 epoch: 78 loss: 18.22757027499879 loss_input: 82.12902393232356
step: 11000 epoch: 78 loss: 18.23450903259248 loss_input: 82.211741004724
step: 12000 epoch: 78 loss: 18.21898331633012 loss_input: 82.19004852419525
step: 13000 epoch: 78 loss: 18.240920595751938 loss_input: 82.2424737328649
step: 14000 epoch: 78 loss: 18.226953222942168 loss_input: 82.21885588843263
step: 15000 epoch: 78 loss: 18.24883066245011 loss_input: 82.20124563717236
Save loss: 18.256401824146508 Name: 78_train_model.pth
step: 0 epoch: 79 loss: 8.996766090393066 loss_input: 56.40167236328125
step: 1000 epoch: 79 loss: 17.975612006344637 loss_input: 81.95525897442401
step: 2000 epoch: 79 loss: 17.99221711728288 loss_input: 81.62572717547476
step: 3000 epoch: 79 loss: 17.997023262766273 loss_input: 81.8569977813385
step: 4000 epoch: 79 loss: 18.064696248785552 loss_input: 82.01299305910827
step: 5000 epoch: 79 loss: 18.127023531946747 loss_input: 81.93371272034656
step: 6000 epoch: 79 loss: 18.114250632846897 loss_input: 81.97878472484403
step: 7000 epoch: 79 loss: 18.1269379757316 loss_input: 82.08033230011505
step: 8000 epoch: 79 loss: 18.150530695632135 loss_input: 82.0803158043355
step: 9000 epoch: 79 loss: 18.21700695061363 loss_input: 82.28633555554374
step: 10000 epoch: 79 loss: 18.2433217716341 loss_input: 82.34178888019402
step: 11000 epoch: 79 loss: 18.218456881792477 loss_input: 82.17485938112516
step: 12000 epoch: 79 loss: 18.221311107177296 loss_input: 82.22567614502991
step: 13000 epoch: 79 loss: 18.229715643511508 loss_input: 82.20519780104054
step: 14000 epoch: 79 loss: 18.238689328387725 loss_input: 82.18824343793383
step: 15000 epoch: 79 loss: 18.240146990736584 loss_input: 82.14178212500677
Save loss: 18.260048995420338 Name: 79_train_model.pth
step: 0 epoch: 80 loss: 20.865009307861328 loss_input: 110.4832763671875
step: 1000 epoch: 80 loss: 18.249217855584966 loss_input: 82.72093659514314
step: 2000 epoch: 80 loss: 18.181602325754007 loss_input: 83.10946104706436
step: 3000 epoch: 80 loss: 18.103685346296412 loss_input: 82.25747960315312
step: 4000 epoch: 80 loss: 18.215768417457557 loss_input: 82.44728023926635
step: 5000 epoch: 80 loss: 18.160136787397008 loss_input: 82.23040585974601
step: 6000 epoch: 80 loss: 18.22693458204964 loss_input: 82.15624629781755
step: 7000 epoch: 80 loss: 18.281149799015637 loss_input: 82.25514506054101
step: 8000 epoch: 80 loss: 18.23733035112497 loss_input: 82.05564259606709
step: 9000 epoch: 80 loss: 18.21300839440132 loss_input: 82.05463165225565
step: 10000 epoch: 80 loss: 18.190257772757118 loss_input: 82.00715934876239
step: 11000 epoch: 80 loss: 18.20385494308898 loss_input: 81.88623834156945
step: 12000 epoch: 80 loss: 18.199658962023594 loss_input: 81.96891399797087
step: 13000 epoch: 80 loss: 18.221929240012184 loss_input: 82.04478595077272
step: 14000 epoch: 80 loss: 18.254390798443666 loss_input: 82.13257217815915
step: 15000 epoch: 80 loss: 18.260825726550607 loss_input: 82.18377951642417
Save loss: 18.254682493701576 Name: 80_train_model.pth
step: 0 epoch: 81 loss: 18.144718170166016 loss_input: 58.41461181640625
step: 1000 epoch: 81 loss: 17.940526279655252 loss_input: 81.55697951950394
step: 2000 epoch: 81 loss: 17.977281608919927 loss_input: 81.79451479094438
step: 3000 epoch: 81 loss: 18.022542283996586 loss_input: 81.56307593920516
step: 4000 epoch: 81 loss: 18.053022249196058 loss_input: 81.48742367630749
step: 5000 epoch: 81 loss: 18.071544724830364 loss_input: 81.45703426453382
step: 6000 epoch: 81 loss: 18.106237003156053 loss_input: 81.84553019036215
step: 7000 epoch: 81 loss: 18.139200537089977 loss_input: 82.08578853446438
step: 8000 epoch: 81 loss: 18.135764549738347 loss_input: 82.18219793601239
step: 9000 epoch: 81 loss: 18.155209300226932 loss_input: 82.1039998715963
step: 10000 epoch: 81 loss: 18.159873716951118 loss_input: 82.28757162125585
step: 11000 epoch: 81 loss: 18.170549679600036 loss_input: 82.29237827744531
step: 12000 epoch: 81 loss: 18.176841591290756 loss_input: 82.22317336287243
step: 13000 epoch: 81 loss: 18.20047145949429 loss_input: 82.21730601927857
step: 14000 epoch: 81 loss: 18.22592808319734 loss_input: 82.25879155168465
step: 15000 epoch: 81 loss: 18.217458189809236 loss_input: 82.21772206153054
Save loss: 18.225159719944 Name: 81_train_model.pth
step: 0 epoch: 82 loss: 20.982776641845703 loss_input: 107.91314697265625
step: 1000 epoch: 82 loss: 18.087896978700314 loss_input: 82.39624627081902
step: 2000 epoch: 82 loss: 18.1003711973054 loss_input: 81.77751001818427
step: 3000 epoch: 82 loss: 18.198944903103282 loss_input: 82.37301447613166
step: 4000 epoch: 82 loss: 18.138826331267563 loss_input: 81.98027106077484
step: 5000 epoch: 82 loss: 18.148648165436036 loss_input: 82.20675918527232
step: 6000 epoch: 82 loss: 18.119858892654065 loss_input: 82.05656763911743
step: 7000 epoch: 82 loss: 18.106156581777313 loss_input: 81.95716554303627
step: 8000 epoch: 82 loss: 18.12737507618095 loss_input: 82.07256538458816
step: 9000 epoch: 82 loss: 18.169926085851944 loss_input: 82.10667299580645
step: 10000 epoch: 82 loss: 18.190808980539554 loss_input: 82.11581015970668
step: 11000 epoch: 82 loss: 18.1967385946301 loss_input: 82.01156301353642
step: 12000 epoch: 82 loss: 18.20124729263138 loss_input: 82.06686654896272
step: 13000 epoch: 82 loss: 18.202151133660013 loss_input: 82.05805157415776
step: 14000 epoch: 82 loss: 18.20447293711291 loss_input: 82.05781323149769
step: 15000 epoch: 82 loss: 18.20707724474405 loss_input: 82.13383568618212
Save loss: 18.207565660715105 Name: 82_train_model.pth
step: 0 epoch: 83 loss: 12.52161979675293 loss_input: 43.55657958984375
step: 1000 epoch: 83 loss: 17.790985984878464 loss_input: 79.84696340036916
step: 2000 epoch: 83 loss: 17.96258275095431 loss_input: 80.94189989965955
step: 3000 epoch: 83 loss: 18.18854228054353 loss_input: 81.78288843090715
step: 4000 epoch: 83 loss: 18.220012985864482 loss_input: 82.18785995639762
step: 5000 epoch: 83 loss: 18.2265685130491 loss_input: 82.35889942372853
step: 6000 epoch: 83 loss: 18.216895191495844 loss_input: 82.0522300645205
step: 7000 epoch: 83 loss: 18.205993767926188 loss_input: 82.0055399451864
step: 8000 epoch: 83 loss: 18.164753760237826 loss_input: 81.7975149880557
step: 9000 epoch: 83 loss: 18.16230501899215 loss_input: 81.78024859217031
step: 10000 epoch: 83 loss: 18.167461720386417 loss_input: 81.83284853277368
step: 11000 epoch: 83 loss: 18.178677439440403 loss_input: 82.0002946232072
step: 12000 epoch: 83 loss: 18.210707004165045 loss_input: 82.23062449873969
step: 13000 epoch: 83 loss: 18.201043583614883 loss_input: 82.23870502674674
step: 14000 epoch: 83 loss: 18.211519903067597 loss_input: 82.18572406920013
step: 15000 epoch: 83 loss: 18.21083810435765 loss_input: 82.22883718152514
Save loss: 18.20190517421067 Name: 83_train_model.pth
step: 0 epoch: 84 loss: 12.108634948730469 loss_input: 60.70538330078125
step: 1000 epoch: 84 loss: 18.03125443206086 loss_input: 81.82202843543176
step: 2000 epoch: 84 loss: 18.28795213248955 loss_input: 82.66338428076001
step: 3000 epoch: 84 loss: 18.16754343699551 loss_input: 81.88332604138465
step: 4000 epoch: 84 loss: 18.1463367714342 loss_input: 81.97448855559547
step: 5000 epoch: 84 loss: 18.166475347413275 loss_input: 82.10097627691259
step: 6000 epoch: 84 loss: 18.168281683264684 loss_input: 82.13789657290191
step: 7000 epoch: 84 loss: 18.19218269400453 loss_input: 82.09907847986003
step: 8000 epoch: 84 loss: 18.159548791404546 loss_input: 81.95793635689337
step: 9000 epoch: 84 loss: 18.131852022185218 loss_input: 81.93886598456291
step: 10000 epoch: 84 loss: 18.142750686317097 loss_input: 81.99779112664905
step: 11000 epoch: 84 loss: 18.156587924451006 loss_input: 81.86971488587153
step: 12000 epoch: 84 loss: 18.16316791769167 loss_input: 81.94897569774459
step: 13000 epoch: 84 loss: 18.171490596336692 loss_input: 82.011918446365
step: 14000 epoch: 84 loss: 18.196624114899777 loss_input: 82.16091207718561
step: 15000 epoch: 84 loss: 18.19327880042321 loss_input: 82.18488885815816
Save loss: 18.202145699709654 Name: 84_train_model.pth
step: 0 epoch: 85 loss: 23.486658096313477 loss_input: 141.5272216796875
step: 1000 epoch: 85 loss: 17.94029935566219 loss_input: 81.7758734795478
step: 2000 epoch: 85 loss: 18.149169778657043 loss_input: 82.90419987760026
step: 3000 epoch: 85 loss: 18.214785958480455 loss_input: 82.55704377024065
step: 4000 epoch: 85 loss: 18.26532498004287 loss_input: 82.57568129024872
step: 5000 epoch: 85 loss: 18.255646598074488 loss_input: 82.72207839926155
step: 6000 epoch: 85 loss: 18.209122218840957 loss_input: 82.68048970394582
step: 7000 epoch: 85 loss: 18.19215424819225 loss_input: 82.57939110679501
step: 8000 epoch: 85 loss: 18.177007599303668 loss_input: 82.41003232597635
step: 9000 epoch: 85 loss: 18.169679703758554 loss_input: 82.31907877748827
step: 10000 epoch: 85 loss: 18.182123666858093 loss_input: 82.28555623441562
step: 11000 epoch: 85 loss: 18.16875007596626 loss_input: 82.32611036270318
step: 12000 epoch: 85 loss: 18.158971173814333 loss_input: 82.27315997084065
step: 13000 epoch: 85 loss: 18.165287823688434 loss_input: 82.1609483455825
step: 14000 epoch: 85 loss: 18.191923200262504 loss_input: 82.22390832731395
step: 15000 epoch: 85 loss: 18.18008075034759 loss_input: 82.21297670731457
Save loss: 18.189113116294145 Name: 85_train_model.pth
step: 0 epoch: 86 loss: 17.08324432373047 loss_input: 84.49188232421875
step: 1000 epoch: 86 loss: 18.15544426143467 loss_input: 82.37978421724759
step: 2000 epoch: 86 loss: 18.06352006525233 loss_input: 81.94452672955515
step: 3000 epoch: 86 loss: 18.053498039957447 loss_input: 81.98453994339127
step: 4000 epoch: 86 loss: 18.078433606720544 loss_input: 81.86906164999277
step: 5000 epoch: 86 loss: 18.04560591406499 loss_input: 81.85194811623613
step: 6000 epoch: 86 loss: 18.108257374670522 loss_input: 82.01254104133686
step: 7000 epoch: 86 loss: 18.130844433330463 loss_input: 82.13060724862966
step: 8000 epoch: 86 loss: 18.16124734498906 loss_input: 82.19358647368786
step: 9000 epoch: 86 loss: 18.200430682441578 loss_input: 82.15742308064947
step: 10000 epoch: 86 loss: 18.18586023313238 loss_input: 82.13114471633891
step: 11000 epoch: 86 loss: 18.171451825920467 loss_input: 82.08646356967371
step: 12000 epoch: 86 loss: 18.161832418613418 loss_input: 82.04974905859082
step: 13000 epoch: 86 loss: 18.176434897943675 loss_input: 82.08887841241028
step: 14000 epoch: 86 loss: 18.181293363137275 loss_input: 82.24234007699226
step: 15000 epoch: 86 loss: 18.18663948534743 loss_input: 82.25279342135654
Save loss: 18.180351336807014 Name: 86_train_model.pth
step: 0 epoch: 87 loss: 21.25572967529297 loss_input: 75.851806640625
step: 1000 epoch: 87 loss: 17.96826394287856 loss_input: 82.09990778264704
step: 2000 epoch: 87 loss: 18.132248714767297 loss_input: 82.27819421588035
step: 3000 epoch: 87 loss: 18.16177808916676 loss_input: 82.59560186074043
step: 4000 epoch: 87 loss: 18.1672552192667 loss_input: 82.31957232859754
step: 5000 epoch: 87 loss: 18.16091221214604 loss_input: 82.3843462630716
step: 6000 epoch: 87 loss: 18.19863257577391 loss_input: 82.26807555999781
step: 7000 epoch: 87 loss: 18.15636506194371 loss_input: 82.22099575548917
step: 8000 epoch: 87 loss: 18.118553236594366 loss_input: 82.24317809120295
step: 9000 epoch: 87 loss: 18.127388461432634 loss_input: 82.24877343137004
step: 10000 epoch: 87 loss: 18.126251588212455 loss_input: 82.1476495905097
step: 11000 epoch: 87 loss: 18.153610885907234 loss_input: 82.28929851259083
step: 12000 epoch: 87 loss: 18.156412518746595 loss_input: 82.17810519879366
step: 13000 epoch: 87 loss: 18.16699148920736 loss_input: 82.18123255186049
step: 14000 epoch: 87 loss: 18.164187367971724 loss_input: 82.1852843205117
step: 15000 epoch: 87 loss: 18.17012229417771 loss_input: 82.18345716649489
Save loss: 18.169509476199746 Name: 87_train_model.pth
step: 0 epoch: 88 loss: 21.069082260131836 loss_input: 83.6107177734375
step: 1000 epoch: 88 loss: 17.849758879883545 loss_input: 81.04419292865337
step: 2000 epoch: 88 loss: 18.025085565032274 loss_input: 81.55339868517889
step: 3000 epoch: 88 loss: 18.12612738413876 loss_input: 81.92709119746543
step: 4000 epoch: 88 loss: 18.091473035590703 loss_input: 81.73934832026856
step: 5000 epoch: 88 loss: 18.110592351820774 loss_input: 81.85343707625663
step: 6000 epoch: 88 loss: 18.10087165234983 loss_input: 81.94210729486166
step: 7000 epoch: 88 loss: 18.07418263385916 loss_input: 81.93499720987124
step: 8000 epoch: 88 loss: 18.131859178081807 loss_input: 82.0238706199933
step: 9000 epoch: 88 loss: 18.14332519723447 loss_input: 82.07730675188651
step: 10000 epoch: 88 loss: 18.13666748025515 loss_input: 81.98580029082052
step: 11000 epoch: 88 loss: 18.144710939284423 loss_input: 81.9119581047941
step: 12000 epoch: 88 loss: 18.148320061993015 loss_input: 82.03039929676271
step: 13000 epoch: 88 loss: 18.15391097068053 loss_input: 82.1000216357681
step: 14000 epoch: 88 loss: 18.157512916461815 loss_input: 82.0920704934999
step: 15000 epoch: 88 loss: 18.157589178054813 loss_input: 82.11701662516118
Save loss: 18.162017346546055 Name: 88_train_model.pth
step: 0 epoch: 89 loss: 11.076813697814941 loss_input: 50.3232421875
step: 1000 epoch: 89 loss: 17.971943085962955 loss_input: 80.63649119435252
step: 2000 epoch: 89 loss: 17.94899821769947 loss_input: 81.12906159835121
step: 3000 epoch: 89 loss: 18.018310186188447 loss_input: 81.37702292595176
step: 4000 epoch: 89 loss: 17.95964930135588 loss_input: 81.53106991501636
step: 5000 epoch: 89 loss: 18.005350017566677 loss_input: 81.92630796350495
step: 6000 epoch: 89 loss: 17.986417241581997 loss_input: 81.94398468785477
step: 7000 epoch: 89 loss: 18.029824559577207 loss_input: 82.07458270295929
step: 8000 epoch: 89 loss: 18.06855959809433 loss_input: 82.1655747621391
step: 9000 epoch: 89 loss: 18.08224646487033 loss_input: 82.15541649479268
step: 10000 epoch: 89 loss: 18.08173141826595 loss_input: 82.09244319708654
step: 11000 epoch: 89 loss: 18.07891510170315 loss_input: 82.12265374445718
step: 12000 epoch: 89 loss: 18.113431888941417 loss_input: 82.24923536950534
step: 13000 epoch: 89 loss: 18.106388567631157 loss_input: 82.2431606494888
step: 14000 epoch: 89 loss: 18.12997596306968 loss_input: 82.20678145966694
step: 15000 epoch: 89 loss: 18.12906084824511 loss_input: 82.16936341613685
Save loss: 18.150845354661346 Name: 89_train_model.pth
step: 0 epoch: 90 loss: 18.632482528686523 loss_input: 54.547607421875
step: 1000 epoch: 90 loss: 18.212572499350472 loss_input: 81.83879981102882
step: 2000 epoch: 90 loss: 18.099182278558292 loss_input: 82.12131647799147
step: 3000 epoch: 90 loss: 18.13952945097809 loss_input: 82.34897305146332
step: 4000 epoch: 90 loss: 18.111681860168407 loss_input: 82.2593314226375
step: 5000 epoch: 90 loss: 18.08454162443764 loss_input: 82.18451588002712
step: 6000 epoch: 90 loss: 18.092133471060347 loss_input: 82.074344278395
step: 7000 epoch: 90 loss: 18.087510175797586 loss_input: 82.19620092288713
step: 8000 epoch: 90 loss: 18.106393587587775 loss_input: 82.14774907134411
step: 9000 epoch: 90 loss: 18.12905571498072 loss_input: 82.24035479754636
step: 10000 epoch: 90 loss: 18.163779482556848 loss_input: 82.30934542654133
step: 11000 epoch: 90 loss: 18.139215180271595 loss_input: 82.10780812584154
step: 12000 epoch: 90 loss: 18.166783829528423 loss_input: 82.16108271698387
step: 13000 epoch: 90 loss: 18.15094868963145 loss_input: 82.16827316055316
step: 14000 epoch: 90 loss: 18.146966436285435 loss_input: 82.13808013347122
step: 15000 epoch: 90 loss: 18.14946449145453 loss_input: 82.18856671762246
Save loss: 18.152102795526385 Name: 90_train_model.pth
step: 0 epoch: 91 loss: 18.133665084838867 loss_input: 75.879638671875
step: 1000 epoch: 91 loss: 18.097583090508735 loss_input: 82.69615260228053
step: 2000 epoch: 91 loss: 17.961043786788093 loss_input: 81.74657315507285
step: 3000 epoch: 91 loss: 18.025804526485707 loss_input: 81.88234990598836
step: 4000 epoch: 91 loss: 18.021458953537067 loss_input: 81.67755627316315
step: 5000 epoch: 91 loss: 18.021314557183626 loss_input: 81.60800432686901
step: 6000 epoch: 91 loss: 18.08484094259322 loss_input: 81.86296604577947
step: 7000 epoch: 91 loss: 18.14482381489937 loss_input: 82.14559711161519
step: 8000 epoch: 91 loss: 18.139415250809666 loss_input: 82.22800452708304
step: 9000 epoch: 91 loss: 18.156724325591572 loss_input: 82.29807008476922
step: 10000 epoch: 91 loss: 18.137244945716265 loss_input: 82.27031532076285
step: 11000 epoch: 91 loss: 18.13207762174829 loss_input: 82.23796367966015
step: 12000 epoch: 91 loss: 18.1367034426372 loss_input: 82.19618187843884
step: 13000 epoch: 91 loss: 18.13849577202484 loss_input: 82.2340882413342
step: 14000 epoch: 91 loss: 18.12403641793653 loss_input: 82.19104241926358
step: 15000 epoch: 91 loss: 18.133404798201262 loss_input: 82.22067950190039
Save loss: 18.13397948296368 Name: 91_train_model.pth
step: 0 epoch: 92 loss: 5.106802940368652 loss_input: 38.54278564453125
step: 1000 epoch: 92 loss: 17.962918370634643 loss_input: 82.81736427634866
step: 2000 epoch: 92 loss: 18.08877594979747 loss_input: 82.76526736021637
step: 3000 epoch: 92 loss: 18.031491543999596 loss_input: 82.40522887634461
step: 4000 epoch: 92 loss: 18.054269877769624 loss_input: 82.37240032338107
step: 5000 epoch: 92 loss: 18.069574383205712 loss_input: 82.27629871974824
step: 6000 epoch: 92 loss: 18.090945750191857 loss_input: 82.2520530432428
step: 7000 epoch: 92 loss: 18.07631770520019 loss_input: 82.1640644354099
step: 8000 epoch: 92 loss: 18.139093140604615 loss_input: 82.21736346219662
step: 9000 epoch: 92 loss: 18.089642912159363 loss_input: 82.18375065395294
step: 10000 epoch: 92 loss: 18.10132992068549 loss_input: 82.17584239500854
step: 11000 epoch: 92 loss: 18.10613618021867 loss_input: 82.1982242780841
step: 12000 epoch: 92 loss: 18.103821269095654 loss_input: 82.14214481658593
step: 13000 epoch: 92 loss: 18.130135361849916 loss_input: 82.21703541490649
step: 14000 epoch: 92 loss: 18.12886550940579 loss_input: 82.24199275944575
step: 15000 epoch: 92 loss: 18.1189134792601 loss_input: 82.16306219233822
Save loss: 18.125070035740734 Name: 92_train_model.pth
step: 0 epoch: 93 loss: 18.71516227722168 loss_input: 75.23468017578125
step: 1000 epoch: 93 loss: 17.851127644995234 loss_input: 81.56827254776474
step: 2000 epoch: 93 loss: 17.918837728886412 loss_input: 81.38285980910912
step: 3000 epoch: 93 loss: 18.035704242750153 loss_input: 81.72926846650076
step: 4000 epoch: 93 loss: 18.031430338061295 loss_input: 81.98259228832929
step: 5000 epoch: 93 loss: 18.049888605261966 loss_input: 82.06437701717469
step: 6000 epoch: 93 loss: 18.050692268459624 loss_input: 82.2834809717586
step: 7000 epoch: 93 loss: 18.045258829856223 loss_input: 82.22503812931858
step: 8000 epoch: 93 loss: 18.086147772879947 loss_input: 82.30316011829088
step: 9000 epoch: 93 loss: 18.09478464612377 loss_input: 82.39448671284788
step: 10000 epoch: 93 loss: 18.08172309273494 loss_input: 82.32971400735903
step: 11000 epoch: 93 loss: 18.07871478911411 loss_input: 82.32541331026015
step: 12000 epoch: 93 loss: 18.092786124185487 loss_input: 82.33205421764983
step: 13000 epoch: 93 loss: 18.08429676816515 loss_input: 82.2246046427919
step: 14000 epoch: 93 loss: 18.09641889532705 loss_input: 82.28578756564124
step: 15000 epoch: 93 loss: 18.118546290680868 loss_input: 82.3158567830504
Save loss: 18.109238894954323 Name: 93_train_model.pth
step: 0 epoch: 94 loss: 19.24112319946289 loss_input: 125.911865234375
step: 1000 epoch: 94 loss: 18.005109757452935 loss_input: 82.19439105816059
step: 2000 epoch: 94 loss: 18.020538966575902 loss_input: 82.26484227978784
step: 3000 epoch: 94 loss: 18.00115657273788 loss_input: 81.97591826487525
step: 4000 epoch: 94 loss: 17.966331479073286 loss_input: 82.09229347021154
step: 5000 epoch: 94 loss: 18.0100724335266 loss_input: 82.06815115248435
step: 6000 epoch: 94 loss: 18.09690254423106 loss_input: 82.2263380094203
step: 7000 epoch: 94 loss: 18.106225456310806 loss_input: 82.42413227204986
step: 8000 epoch: 94 loss: 18.145189582251145 loss_input: 82.65190551132281
step: 9000 epoch: 94 loss: 18.157321118921747 loss_input: 82.48457469162497
step: 10000 epoch: 94 loss: 18.13271343168074 loss_input: 82.27819929188722
step: 11000 epoch: 94 loss: 18.105148669384075 loss_input: 82.2098573036773
step: 12000 epoch: 94 loss: 18.109999672371828 loss_input: 82.2896484090193
step: 13000 epoch: 94 loss: 18.119283249117615 loss_input: 82.33720146433298
step: 14000 epoch: 94 loss: 18.110958780699836 loss_input: 82.29402218950739
step: 15000 epoch: 94 loss: 18.103317597795904 loss_input: 82.25796552121135
Save loss: 18.11340883333981 Name: 94_train_model.pth
step: 0 epoch: 95 loss: 19.585969924926758 loss_input: 85.1544189453125
step: 1000 epoch: 95 loss: 17.98781127434272 loss_input: 81.24488853431724
step: 2000 epoch: 95 loss: 18.11878186949845 loss_input: 82.12724359865966
step: 3000 epoch: 95 loss: 18.007362709884365 loss_input: 81.83159003151293
step: 4000 epoch: 95 loss: 18.001642264237674 loss_input: 81.74925088918201
step: 5000 epoch: 95 loss: 17.990261971676404 loss_input: 81.7914618736409
step: 6000 epoch: 95 loss: 18.042893550451986 loss_input: 82.11918704467224
step: 7000 epoch: 95 loss: 18.071082813980546 loss_input: 82.2751495618511
step: 8000 epoch: 95 loss: 18.053465560411993 loss_input: 82.2720295491628
step: 9000 epoch: 95 loss: 18.034959349469627 loss_input: 82.19998713793086
step: 10000 epoch: 95 loss: 18.019462081339704 loss_input: 82.08239043039056
step: 11000 epoch: 95 loss: 18.054182662691662 loss_input: 82.1037662514079
step: 12000 epoch: 95 loss: 18.05146494822426 loss_input: 82.26619394265973
step: 13000 epoch: 95 loss: 18.05462805178246 loss_input: 82.24636135918482
step: 14000 epoch: 95 loss: 18.09089050646484 loss_input: 82.28162962463479
step: 15000 epoch: 95 loss: 18.101403711795903 loss_input: 82.2912724071976
Save loss: 18.0918621314466 Name: 95_train_model.pth
step: 0 epoch: 96 loss: 17.813045501708984 loss_input: 77.3037109375
step: 1000 epoch: 96 loss: 17.93382795040424 loss_input: 81.58871371548373
step: 2000 epoch: 96 loss: 17.975326289063034 loss_input: 81.31189898214954
step: 3000 epoch: 96 loss: 17.933593014485435 loss_input: 80.87848703752395
step: 4000 epoch: 96 loss: 17.967405173814885 loss_input: 81.42674666111304
step: 5000 epoch: 96 loss: 17.974188976539562 loss_input: 81.59237448164664
step: 6000 epoch: 96 loss: 18.026927147045114 loss_input: 81.76429453326789
step: 7000 epoch: 96 loss: 18.007190455506315 loss_input: 81.88330616029462
step: 8000 epoch: 96 loss: 17.994194729628227 loss_input: 81.6952473607425
step: 9000 epoch: 96 loss: 18.027179652194874 loss_input: 81.8931833094934
step: 10000 epoch: 96 loss: 18.00967962941388 loss_input: 81.83336615068961
step: 11000 epoch: 96 loss: 18.02730831890992 loss_input: 81.88197435265118
step: 12000 epoch: 96 loss: 18.026467882328337 loss_input: 81.92976551677334
step: 13000 epoch: 96 loss: 18.044657204428248 loss_input: 81.95558973397029
step: 14000 epoch: 96 loss: 18.053301933262826 loss_input: 82.00630018300869
step: 15000 epoch: 96 loss: 18.074637808344235 loss_input: 82.20856023335423
Save loss: 18.081146730437876 Name: 96_train_model.pth
step: 0 epoch: 97 loss: 13.552120208740234 loss_input: 57.50531005859375
step: 1000 epoch: 97 loss: 17.994875953152224 loss_input: 82.08163363735873
step: 2000 epoch: 97 loss: 17.953625272953886 loss_input: 81.87007829703312
step: 3000 epoch: 97 loss: 17.89855845115138 loss_input: 81.68505324478429
step: 4000 epoch: 97 loss: 17.976784233628617 loss_input: 82.0160965312871
step: 5000 epoch: 97 loss: 18.004078364233997 loss_input: 82.44340221311207
step: 6000 epoch: 97 loss: 17.984195100567852 loss_input: 82.39119445465144
step: 7000 epoch: 97 loss: 17.983096083374196 loss_input: 82.20057925597682
step: 8000 epoch: 97 loss: 18.016357226932573 loss_input: 82.36388838236041
step: 9000 epoch: 97 loss: 18.020160470137583 loss_input: 82.4551528237314
step: 10000 epoch: 97 loss: 18.034659787900758 loss_input: 82.4421179525114
step: 11000 epoch: 97 loss: 18.076110039740385 loss_input: 82.38508533137613
step: 12000 epoch: 97 loss: 18.071522141504204 loss_input: 82.43460364000428
step: 13000 epoch: 97 loss: 18.064223017640117 loss_input: 82.31871425305025
step: 14000 epoch: 97 loss: 18.068570336531966 loss_input: 82.26780991124797
step: 15000 epoch: 97 loss: 18.053986550839646 loss_input: 82.18586955449715
Save loss: 18.070884434342386 Name: 97_train_model.pth
step: 0 epoch: 98 loss: 30.728195190429688 loss_input: 70.526123046875
step: 1000 epoch: 98 loss: 18.117451151410542 loss_input: 82.18806266975213
step: 2000 epoch: 98 loss: 18.120925280643903 loss_input: 83.31996016762126
step: 3000 epoch: 98 loss: 18.105526308900554 loss_input: 83.31613916780344
step: 4000 epoch: 98 loss: 18.077231052487353 loss_input: 83.04961062895897
step: 5000 epoch: 98 loss: 18.061123789417532 loss_input: 82.77459409241199
step: 6000 epoch: 98 loss: 18.04242245377431 loss_input: 82.47835999094552
step: 7000 epoch: 98 loss: 18.052422143139 loss_input: 82.46969907444863
step: 8000 epoch: 98 loss: 18.04035047027055 loss_input: 82.4766439107221
step: 9000 epoch: 98 loss: 18.049900504830493 loss_input: 82.57062865410788
step: 10000 epoch: 98 loss: 18.03214489034552 loss_input: 82.47364497559033
step: 11000 epoch: 98 loss: 18.034728199273346 loss_input: 82.39102270776343
step: 12000 epoch: 98 loss: 18.03401882111475 loss_input: 82.33037927788244
step: 13000 epoch: 98 loss: 18.042025021980034 loss_input: 82.35020022028804
step: 14000 epoch: 98 loss: 18.04974843149449 loss_input: 82.32900314598065
step: 15000 epoch: 98 loss: 18.05548272472359 loss_input: 82.29362098923222
Save loss: 18.06892393167317 Name: 98_train_model.pth
step: 0 epoch: 99 loss: 17.688148498535156 loss_input: 89.88641357421875
step: 1000 epoch: 99 loss: 17.95951832019604 loss_input: 81.52477423699348
step: 2000 epoch: 99 loss: 17.950049174421732 loss_input: 81.74485624009284
step: 3000 epoch: 99 loss: 18.02797518615443 loss_input: 81.95807153230824
step: 4000 epoch: 99 loss: 18.01397395175685 loss_input: 81.80802080363698
step: 5000 epoch: 99 loss: 18.021521435859466 loss_input: 81.83036293131998
step: 6000 epoch: 99 loss: 18.00100298608031 loss_input: 81.7986545801123
step: 7000 epoch: 99 loss: 17.960495034961458 loss_input: 81.67417893112089
step: 8000 epoch: 99 loss: 17.97504222412405 loss_input: 81.75175938548453
step: 9000 epoch: 99 loss: 17.98582521765355 loss_input: 81.84158745952055
step: 10000 epoch: 99 loss: 18.006919867944006 loss_input: 82.0768528066627
step: 11000 epoch: 99 loss: 18.029034484224898 loss_input: 82.034755673845
step: 12000 epoch: 99 loss: 18.021595849602257 loss_input: 82.07554599637042
step: 13000 epoch: 99 loss: 18.034104863823988 loss_input: 82.14433322493072
step: 14000 epoch: 99 loss: 18.057589343322803 loss_input: 82.20226615718855
step: 15000 epoch: 99 loss: 18.067401198639597 loss_input: 82.26294470586727
Save loss: 18.058066804900765 Name: 99_train_model.pth
